[ { "title": "SOLID", "url": "/posts/solid/", "categories": "SoftwareEngineering", "tags": "", "date": "2021-03-17 19:09:00 +0800", "snippet": "SOLID Principle SRP(Single Responsibility Principle) : 단일 책임 원칙, 클래스는 단 하나의 책임을 가져야 하며 클래스를 변경하는 이유는 단 하나의 이유이어야 한다. OCP(Open-Closed Principle) : 개방-폐쇄 원칙, 확장에는 열려 있어야 하고 변경에는 닫혀 있어야 한다. LSP(Liskov Substitution Principle) : 리스코프 치환 원칙, 상위 타입의 객체를 하위 타입의 객체로 치환해도 프로그램은 동작해야 한다. 예시 ..." }, { "title": "DataFrame", "url": "/posts/dataframe/", "categories": "DataEngineering, Spark", "tags": "", "date": "2021-03-16 10:35:00 +0800", "snippet": "DataFrame named column으로 정리된 분산 데이터 컬렉션Optimization, Code Generation실행이 query optimizer에 의해 최적화된다. DataFrame에 대한 계산이 시작되기전에, Catalyst Optimizer가 DataFrame을 만드는 작업을 실행을 위한 physical plan으로 변환한다. 그리고 operation의 semantic과 데이터 구조를 분석하여, 계산을 빠르게 최적화한다.high level 관점에서 두가지 종류의 최적화가 존재한다. Catalyst는 predi..." }, { "title": "Shuffle", "url": "/posts/shuffle/", "categories": "DataEngineering, Spark", "tags": "", "date": "2021-03-14 23:48:00 +0800", "snippet": "Spark Architecture: ShuffleShuffle 이란 무엇일까? 하루에 발생한 전화량을 계산한다고 가정해보자. 이 경우 “day”를 key로 설정할것이고, 각각의 value는 1로 설정할것이다. 그리고 각각의 key에 대해서 value들을 합할것이다. 하지만 데이터를 클러스터에 저장할때, 같은 key에 대한 value들을 어떻게 계산할 수 있을까? 유일한 방법은 같은 key에 대한 value들이 같은 머신에 있도록 하는 방법 뿐이다.이 주제를 논의하기에 앞서, 이 글에서는 MapReduce naming coven..." }, { "title": "Cookie", "url": "/posts/cookie/", "categories": "Web", "tags": "", "date": "2021-03-14 14:38:00 +0800", "snippet": "HTTP cookie 웹사이트를 브라우징 하면서 사용자의 컴퓨터에 저장되는 작은 데이터. web cooke, Internet cookie, browser cookie, or cookie 라고 부른다.쿠키는 웹사이트가 사용자의 활동정보(특정 버튼 클릭, 로그인, 이전에 방문한 사이트 정보, online store에서 쇼핑 카트 정보)를 기억하기 위해서 사용된다.Session cookie유저가 웹사이트를 이용중인동안에만 임시 메모리에 존재하는 cookie이다. 브라우저가 종료되면 보통 삭제된다." }, { "title": "Transformation,Action", "url": "/posts/transformationaction/", "categories": "DataEngineering, Spark", "tags": "", "date": "2021-03-13 17:30:00 +0800", "snippet": "Transformation Operation1. Transformationdataset을 함수에 전달하고 새로운 dataset을 리턴하는 작업lazy evaluation 이고 action이 실행될때 실행된다. 두가지 기본타입은 map(),filter()이다. Narrow transformation - 하나의 파티션에서 일부만이 결과로 반환된다. Wide transformation - 하나의 파티션에 있는 데이터가 여러 파티션에 보내질수있다. 대표적으로 groupbyKey()와 reducebyKey가..." }, { "title": "Log Compaction", "url": "/posts/log-compaction/", "categories": "DataEngineering, Kafka", "tags": "", "date": "2021-03-13 11:23:00 +0800", "snippet": "Log CompactionKafka는 시간,크기에 따라서 예전 로그들을 삭제할수 있다. 카프카는 또한 record key에 대한 log compaction도 지원한다.Log compaction 이란 레코드의 최근 버전만 유지하고 이전 버전은 삭제하는 것을 말한다.구조log는 head와 tail을 가지고 있다. compacted log의 head는 전통적인 카프카 로그와 같다. 새로운 레코드들이 head의 끝에 append 된다. 모든 log compaction은 log의 tail에서 작동한다. 오직 tail만이 compact된..." }, { "title": "함수형 프로그래밍의 정의와 장단점", "url": "/posts/%ED%95%A8%EC%88%98%ED%98%95-%ED%94%84%EB%A1%9C%EA%B7%B8%EB%9E%98%EB%B0%8D%EC%9D%98-%EC%A0%95%EC%9D%98%EC%99%80-%EC%9E%A5%EB%8B%A8%EC%A0%90/", "categories": "Language, Scala", "tags": "", "date": "2021-03-13 09:27:00 +0800", "snippet": "함수형 프로그래밍어떻게 문제를 해결할지 보다 무엇을 해결할지에 초점을 맞춘 declarative type of programming이다. Clojure, Common Lisp, Erlang, Haskell, Scala가 유명한 functional programming language이다. 프로그래밍 패러다임은 lambda calculus에 기반한다.Lambda Calculusstatement 대신 expression을 사용한다. 값을 할당하기 위해 실행되는 statement와 달리, expression의 evaluation은 ..." }, { "title": "HDFS append 동작방식", "url": "/posts/hdfs-append-%EB%8F%99%EC%9E%91%EB%B0%A9%EC%8B%9D/", "categories": "DataEngineering, Hadoop", "tags": "", "date": "2021-03-12 19:54:00 +0800", "snippet": "HDFS append 동작방식 HDFS는 마지막 블럭에 append한다. 그리고 만약 블럭이 가득차면 새로운 블럭을 생성한다. 오직 하나의 write or append만이 특정 시점에 허용된다. 다른 인스턴스가 write or append하려면 파일을 닫아야한다. 마지막 블럭이 복제되지 않으면, append는 실패한다. append는 single replica에 기록이되고, replicas에게 복제된다.출처https://issues.apache.org/jira/browse/HDFS-265" }, { "title": "Case Class", "url": "/posts/case-class/", "categories": "Language, Scala", "tags": "", "date": "2021-03-12 14:39:00 +0800", "snippet": "Case Class regular class와 몇가지 특성을 제외하고 비슷하다. immutable data를 모델링하는데 좋다.case class 정의하기case class Book(isbn: String)val frankenstein = Book(&quot;978-0486282114&quot;)Book case class를 생성할때 new 키워드가 사용이 되지 않음을 알수 있다. 이유는 case class가 apply method를 기본적으로 가지고 있어서, object 생성을 하기 때문이다.case class Messag..." }, { "title": "Type class pattern vs implicit class", "url": "/posts/type-class-pattern-vs-implicit-class/", "categories": "Language, Scala", "tags": "", "date": "2021-03-12 14:25:00 +0800", "snippet": "Type class pattern vs implicit classimplicit class는 보통 존재하는 타입에 대한 extention method를 제공하는데 사용된다.implicit class IntExt(val x: Int) extends AnyVal { def squared: Int = x * x}10.squared shouldEqual 1000Type class는 ad-hoc polymorphism을 제공한다.trait Show[T] { def show(x: T): String}implicit val intHex..." }, { "title": "Python to RDD communications", "url": "/posts/pyspark/", "categories": "DataEngineering, Spark", "tags": "", "date": "2021-03-11 20:26:00 +0800", "snippet": "Py4J와 PysparkPy4J는 Python 인터프리터에서 실행되는 Python프로그램이 JVM(Java Virtual Machine)의 Java 객체에 동적으로 액세스가 가능하게 한다. 또한 Py4J는 자바 프로그램이 Python 객체와 연동할 수 있게하며, BSD 라이센스하에 배포된다. Method는Python interpreter에 있는 Java 객체와 Java collection이 표준 Python collection method를 통해 액세스 할 수 있는 것처럼 호출된다. PySpark는 Spark의 Java API..." }, { "title": "Certificate Authority", "url": "/posts/certificate-authority/", "categories": "Security", "tags": "", "date": "2021-03-11 13:46:00 +0800", "snippet": "SSL certificates세가지 안전한 커뮤니케이션을 위한 원칙 존재한다. Data Encryption Data Integrity Data Authenticity : 의도하고 있는 대상과 커뮤니케이션 하고 있는가SSL은 Data Authenticity를 고려하기 위해 존재한다.SSL certificate은 Certificate Authority(CA)라 불리는 기관에 의해서 private key를 사용하여 서명된 binary이다.브라우저가 신뢰하는 certificate은 두가지 타입이있다. Root CA : Glob..." }, { "title": "Private Constructor", "url": "/posts/private-constructor/", "categories": "Java", "tags": "", "date": "2021-03-11 10:42:00 +0800", "snippet": "Private Constructor 사용하는 경우 class내에 있는 static factory method 만을 사용해서 객체를 생성해야하는 경우 static 함수만 포함하고 있는 utility class의 경우" }, { "title": "Data Processing Architecture", "url": "/posts/data-processing-architecture/", "categories": "DataEngineering, Concept", "tags": "", "date": "2021-03-10 13:59:00 +0800", "snippet": "Data Processing ArchitectureLambda Architecturetraditional batch 파이프라인을 fast real-time stream pipeline을 결합하기 위해서 사용하는 data processing을 위한 deployment model.Data Sources데이터가 동시에 batch layer와 speed layer에 전달된다.Batch Layer데이터는 immutable, append-only로 간주된다.Serving Layer점진적으로 최근 batch view을 인덱싱한다. 인덱싱 ..." }, { "title": "Citus", "url": "/posts/citus/", "categories": "Database, PostgreSQL", "tags": "", "date": "2021-03-09 12:35:00 +0800", "snippet": "Citus란?여러 머신에 쿼리하고 데이터를 분산할수 있도록 하는 PostgreSQL의 extension. sharding과 replication을 사용해서 수평확장한다.언제 사용하는가?1. Multi-Tenant Database 모든 tenant에 빠른 쿼리가능 database에 sharding logic이 있음 단일 노드 PostgreSQL보다 더 많은 데이터 소유가능 SQL을 포기하는것 없이 Scale out high concurrency를 보장하고 동시에 퍼포먼스도 유지 빠른 metric 분석가능 신규 사용자..." }, { "title": "Message Queue 사용이유", "url": "/posts/message-queue-%EC%82%AC%EC%9A%A9%EC%9D%B4%EC%9C%A0/", "categories": "DataEngineering, Kafka", "tags": "", "date": "2021-03-08 09:50:00 +0800", "snippet": "Message Queue를 사용하는 이유?1. Performance 개선메시지를 컨슈밍하고 프로듀싱하는 endpoint들이 서로 통신하는것이 아니라, queue를 통해서 통신한다. producer는 consumer가 처리할때까지 기다릴 필요없이 publish가능하고, consumer는 데이터가 있을때 컨슈밍할수 있다. producer와 consumer가 서로서로 기다릴 필요가 없기 때문에 data flow를 최적화 할수 있다.2. 신뢰성 향상Queue하나가 다운되더라도 다른 queue가 대신해서 데이터를 제공해줄수 있다.3. ..." }, { "title": "Kinesis", "url": "/posts/kinesis/", "categories": "DataEngineering, Kinesis", "tags": "", "date": "2021-03-07 12:44:00 +0800", "snippet": "Kinesis Amazon Kinesis는 Amazon의 Kafka Amazon은 자체 생태계가 있음 Elastic MapReduce(EMR) S3 Elasticsearch Service / CloudSearch DynamoDB Amazon RDS ElastiCache AI/ Machine Learning services EMR은 Hadoop cluster를 돌리기 편한 방법임." }, { "title": "Redis", "url": "/posts/redis/", "categories": "Database, Redis", "tags": "", "date": "2021-03-07 12:39:00 +0800", "snippet": "Redis Distributed in-memory data store(memcache와 유사) 자료구조들을 저장하기 좋음 데이터를 디스크로 저장가능 데이터 스토어로도 사용가능 web apps에 대한 caching layer로 많이 사용됨" }, { "title": "Accumulo", "url": "/posts/accumulo/", "categories": "DataEngineering, Accumulo", "tags": "", "date": "2021-03-07 12:37:00 +0800", "snippet": "Accumulo BigTable clone(HBase와 유사) 보안 모델 제공 Cell-based access control Server-side programming 복잡한 보안 요구사항이 있을경우 사용" }, { "title": "Apache Flink vs Apache Spark", "url": "/posts/apache-flink-vs-apache-spark/", "categories": "DataEngineering, Concept", "tags": "", "date": "2021-03-05 22:50:00 +0800", "snippet": "Apache Flink vs Apache Spark Features Apache Flink Apache Spark Computation Model operator 기반 computational model micro-batch 기반 model Streaming Engine 모든 작업에 대해서 stream을 사용 : streaming, SQL, micro-batch, batch. Batch는 finite set o..." }, { "title": "Garbage Collection", "url": "/posts/garbage-collection/", "categories": "Java", "tags": "", "date": "2021-03-04 21:08:00 +0800", "snippet": "Garbage Collection 동작방식Java garbage collection은 라이브 오브젝트들을 추적하고 다른 오브젝트들은 garbage로 간주한다.OS는 미리 JVM이 필요한 heap영역을 할당한다. 객체생성이 더 빠르다(OS가 관여하지 않기 때문). 메모리할당은 메모리 배열의 일부를 차지하고 offset을 앞으로 옮기기만 하면된다. 다음 할당은 이 offset부터 시작한다. 객체가 더이상 사용되지 않으면, garbage collector가 메모리를 다시 차지하고 추후 객체할당에 사용한다. 이는 아무런 명시적인 ..." }, { "title": "Process vs Thread", "url": "/posts/process-vs-thread/", "categories": "OS", "tags": "", "date": "2021-03-04 12:10:00 +0800", "snippet": "Process vs ThreadProcessPCB는 어느 프로세스의 동작을 통제함. PID, Process Priority, Process State 등을 포함한다. 다른 프로세스와 메모리를 공유하지 않는다.Thread프로세스의 일부이고 3가지 상태를 가질수 있다 : running,ready,blocked. Thread는 프로세스에 비해서 종료시간이 짧다. 여러 스레드들은 데이터,코드,파일 등의 정보를 공유한다. 세가지 방법으로 스레드를 구현할수 있다. Kernel-level thread User-level thread ..." }, { "title": "JVM", "url": "/posts/jvm/", "categories": "Java", "tags": "", "date": "2021-03-03 17:52:00 +0800", "snippet": "JVMJava code나 어플리케이션을 실행하기위한 런타임 환경을 제공한다. Java bytecode를 machine language로 변환한다. JVM은 JRE(Java Run Environment)의 일부이다.JVM 작동방식먼저 Java code가 bytecode로 컴파일된다. 이 바이트 코드는 다른 머신에서 해석된다. 바이트코드는 소스코드와 호스트 시스템을 연결하는 언어이다.JVM Architecture1. ClassLoaderclass 파일들을 로딩하는데 사용되는 시스템이다. Loading,Linking,Initiali..." }, { "title": "Elasticsearch _rollover API 사용하여, 효율적인 저장 분배", "url": "/posts/elasticsearch-_rollover-api-%EC%82%AC%EC%9A%A9%ED%95%98%EC%97%AC-%ED%9A%A8%EC%9C%A8%EC%A0%81%EC%9D%B8-%EC%A0%80%EC%9E%A5-%EB%B6%84%EB%B0%B0/", "categories": "Database, Elasticsearch", "tags": "", "date": "2021-03-02 15:47:00 +0800", "snippet": "Elasticsearch _rollover API 사용하여, 효율적인 저장 분배Skew란?데이터가 전체 샤드에 골고루 분배되지 않는 상황Rollover를 사용하여 해결하기_rollover API는 임계치를 넘어가면 새로운 인덱스를 생성한다.POST _aliases{ &quot;actions&quot;: [ { &quot;add&quot;: { &quot;index&quot;: &quot;weblogs-000001&quot;, &quot;alias&quot;: &quot;weblogs&..." }, { "title": "Spark vs MapReduce", "url": "/posts/spark-vs-mapreduce/", "categories": "DataEngineering, Spark", "tags": "", "date": "2021-02-25 16:59:00 +0800", "snippet": "Spark이 MapReduce보다 더 빠른 이유 task start up time이 더빠름. Spark은 thread를 복제하고, MR은 새로운 JVM을 생성 Faster shuffle. 셔플과정에서 Spark은 데이터를 HDD에 한번만 넣고, MR은 2번 넣는다. Faster workflow. 전형적인 MR workflow는 일련의 MR job이고, 각각의 job은 데이터를 반복할때마다 HDFS에 데이터를 저장한다. Spark은 DAG을 지원하고 파이프라이닝을 지원한다, 중간 결과를 저장할 ..." }, { "title": "Spark Architecture", "url": "/posts/spark-architecture/", "categories": "DataEngineering, Spark", "tags": "", "date": "2021-02-25 13:56:00 +0800", "snippet": "Driver Spark Shell(Scala, Python, R)에 대한 entry point SparkContext가 생성되는 곳 RDD를 execution graph로 변환 graph를 여러 stage로 나눔 task를 스케줄하고 실행을 통제 RDD와 파티션에 대한 메타데이터 저장 Executor JVM heap or HDD에 데이터 저장 외부 저장소로부터 데이터 읽어들임 외부 저장소에 데이터를 씀 데이터..." }, { "title": "Executor 자원 결정하기", "url": "/posts/executor-%EC%9E%90%EC%9B%90-%EA%B2%B0%EC%A0%95%ED%95%98%EA%B8%B0/", "categories": "DataEngineering, Spark", "tags": "", "date": "2021-02-25 13:46:00 +0800", "snippet": "Executor 자원 결정하기 JVM heap은 64gb미만이어야한다. 40gb가 적당한것으로 보인다. 이유는 garbage collection 때문인데 만약 executor가 너무 커지면 GC가 어플리케이션 성능에 영향을 준다. executor는 4코어를 넘어서는 안된다. 4 코어는 1코어의 throughput에 비해 4배가량 성능을 내는것처럼 보인다. 5 코어에서는 4.3-4.5배 정도 성능을 내는것처럼 보인다. 여러 large executor가 일반적으로 여러 small executor보다 좋다. executor수가..." }, { "title": "Schema Evolution", "url": "/posts/schema-evolution/", "categories": "DataEngineering, Kafka", "tags": "", "date": "2021-02-25 09:10:00 +0800", "snippet": "Kafka Avro Serializer 순서 Producer는 메시지를 직렬화 하기 위해 KafkaAvroSerializer를 사용 kafkaAvroSerializer는 SchemaRegistryClient라는 것을 사용하여 Schema Registry에 스키마정보를 등록 Schema Registry에 정상적으로 스키마가 등록되면 SchemaID를 반환 KafkaAvroSerializer는 SchemaID와 메시지 본문을 포함한 데이터를 직렬화 함 직렬..." }, { "title": "Cache,Persist", "url": "/posts/cachepersist/", "categories": "DataEngineering, Spark", "tags": "", "date": "2021-02-23 13:19:00 +0800", "snippet": "Spark DataFrame Cache, PersistSpark Cache,Persist는 잡의 퍼포먼스를 개선하기위해 반복적이고 상호작용이 많은 spark 어플리케이션에 대해서 DataFrame/Dataset을 최적화 하는 기술이다.cache() 와 persist() 함수를 사용하여, spark은 데이터 프레임 중간 결과를 저장하는 최적화 메커니즘을 제공하여, 연속적인 액션들이 재사용될수 있도록 한다.데이터 셋을 persist할때, 각 노드는 partition된 데이터를 메모리에 저장하고 그 데이터셋에 대해서 다른 actio..." }, { "title": "Spark Memory Architecture", "url": "/posts/spark-memory-architecture/", "categories": "DataEngineering, Spark", "tags": "", "date": "2021-02-13 16:44:00 +0800", "snippet": "Spark Legacy Memory ArchitectureExecutorworker node 에서 수행되는 Spark application의 JVM process이다. 여러 스레드로 task들을 수행하며 관련있는 데이터 파티션들을 유지한다.Executor Memory 구조YARN에 10gb의 executor을 워커노드상에서 요청할때, 10gb 전체가 이용가능하다고 생각하기 쉽지만 사실 safety 리전이 존재한다. 이는 OOM을 방지 하기 위한 공간이다. safety 공간은 10%점유하고 configuration에는 spark..." }, { "title": "Pipfile", "url": "/posts/pipfile/", "categories": "Language, Python", "tags": "", "date": "2021-02-11 22:10:00 +0800", "snippet": "Pipfile프로젝트 의존성을 관리하기 위해 Pipenv virtual environment에 의해 사용되는 dedicated filepython_version 파라미터는 pipenv 환경을 생성했을때 명시한 base interpreter 버전을 의미한다. packages는 프로젝트에 필요한 패키지 리스트를 명시할때 사용한다." }, { "title": "[Trouble Shooting] cannot resolve column(numeric column name) in Spark Dataframe", "url": "/posts/trouble-shooting-cannot-resolve-columnnumeric-column-name-in-spark-dataframe/", "categories": "DataEngineering, Spark", "tags": "", "date": "2021-02-10 08:59:00 +0800", "snippet": "다음과 같은 스키마가 있다고 하자.scala&amp;gt; data.printSchemaroot |-- 1.0: string (nullable = true) |-- 2.0: string (nullable = true) |-- 3.0: string (nullable = true)이 경우 다음 라인을 실행하면 에러가 난다.scala&amp;gt; data.select(&quot;2.0&quot;).showException: org.apache.spark.sql.AnalysisException: cannot resolve ‘2.0..." }, { "title": "중첩된 schema flattening하기", "url": "/posts/%EC%A4%91%EC%B2%A9%EB%90%9C-schema-flattening%ED%95%98%EA%B8%B0/", "categories": "DataEngineering, Spark", "tags": "", "date": "2021-02-10 08:56:00 +0800", "snippet": "def flattenSchema(schema: StructType, prefix: String = null): Array[Column] = { schema.fields.flatMap(f =&amp;gt; { val colName = if (prefix == null) f.name else (prefix + &quot;.&quot; + f.name) f.dataType match { case st: StructType =&amp;gt; flattenSchema(st, colName) ..." }, { "title": "Scala return", "url": "/posts/scala-return/", "categories": "Language, Scala", "tags": "", "date": "2021-02-10 08:50:00 +0800", "snippet": "Scala에서는 return 키워드가 없다면 마지막 expression이 return value로 간주된다.def f() = { if (something) &quot;A&quot; else &quot;B&quot;}위의 코드의 경우 리턴타입은 String이 된다.def f() = { if (something) &quot;A&quot; else &quot;B&quot; if (somethingElse) 1 else 2}위의 코드의 경우 리턴타입은 Int가 된다." }, { "title": "Avro vs Parquet", "url": "/posts/avro-vs-parquet/", "categories": "DataEngineering, Concept", "tags": "", "date": "2021-02-02 21:35:00 +0800", "snippet": "Apache Avro vs ParquetApache Avro 는 remote procedure call과 data serialization framework 이고 Apache Hadoop project중 개발되었다. type,protocol을 정의하는데 JSON을 사용하고 compact binary format으로 데이터를 직렬화한다. row based format이기 때문에, 모든필드들이 접근될필요가 있을때 사용하는것이 좋다. 파일들은 block compression을 지원하고 쪼개질수있다. streaming data로..." }, { "title": "RDDs vs DataFrames vs Datasets", "url": "/posts/rdds-vs-dataframes-and-datasets/", "categories": "DataEngineering, Spark", "tags": "", "date": "2021-02-02 17:39:00 +0800", "snippet": "Resilient Distributed Dataset(RDD)RDD는 데이터의 immutable distributed collection, 클러스터의 노드들에 분할되어있고 병렬적으로 처리됨.언제 RDD를 사용하는가? dataset에 대해서, low-level transformation, action, control이 필요할때 media stream, text stream과 같이 데이터가 unstructured 구조일때 functional programming으로 데이터를 다루고 싶을때 columnar format과 같은..." }, { "title": "HDFS Connector 2", "url": "/posts/hdfs-connector-2/", "categories": "DataEngineering, Kafka", "tags": "", "date": "2021-01-30 21:01:00 +0800", "snippet": "HDFS 2 Sink Connector 다양한 포맷의 HDFS 2.x 파일로 카프카 토픽 데이터를 저장할수 있는 카프카 커넥터 HiveQL로 쿼리할수 있도록 제공 커넥터는 주기적으로 카프카로부터 데이터를 poll하고 HDFS에 쓴다. 카프카 토픽의 데이터는 제공된 partitioner의 의해 분할되고 chunk로 나눠진다. 하나의 데이터 chunk는 topic, kafka partition, start.end offset을 파일명으로 갖는 HDFS 파일로 표현된다. partioner가 명시되지 않는경우,..." }, { "title": "FQDN", "url": "/posts/fqdn/", "categories": "etc", "tags": "", "date": "2021-01-30 18:14:00 +0800", "snippet": "FQDN(Fully Qualified Domain Name)FQDN은 명확한 도메인 표기법을 칭한다. 예로 소프트웨어 설치 중 도메인명을 요구하면, YAHOO.COM. 을 입력할지, WWW.YAHOO.COM. 을 입력할지 모호하다. 그래서 이러한 모호성을 피하기 위해 FQDN이란 단어를 사용하며, 이는 Namespace 계층상에서 최종 호스트명을 포함하는 도메인명을 뜻한다.www(호스트명), yahoo.com.(도메인명), www.yahoo.com.(FQDN)원칙적으로 도메인의 표기는 네임스페이스상의 경로를 명확히 하기 위해 ..." }, { "title": "Searchable snapshot vs es for hadoop", "url": "/posts/searchable-snapshot-vs-es-for-hadoop/", "categories": "Database, Elasticsearch", "tags": "", "date": "2021-01-25 10:21:00 +0800", "snippet": "Searchable SnapshotSnapshotsnapshot이란 실행중인 Elasticsearch cluster에 대한 백업이다. 모든 데이터 스티림, 인덱스들을 포함하여, 전체 클러스터에 대한 스냅샷을 생성가능하다. 특정 데이터 스트림 또는 인덱스에대한 스냅샷또한 생성가능하다.스냅샷을 생성하기전에 snapshot repository를 등록해야한다. 스냅샷은 로컬 또는 원격 저장소에서 저장이 가능하다. 원경저장소는 Amazon S3, HDFS, Microsoft Azure, Google Cloud Storage와 그리고 다..." }, { "title": "Hive Internal table, External table", "url": "/posts/hive-internal-table-external-table/", "categories": "DataEngineering, Hadoop", "tags": "", "date": "2021-01-24 14:05:00 +0800", "snippet": "Internal TableHive에서 디폴트로 테이블을 생성하면, Internal table로 생성이 되고, 이를 Managed table이라고도 부른다. internal table들이 생성한 모든 데이터베이스들은 디폴트로 hdfs의 /user/hive/warehouse 경로에 저장된다. 디폴트 저장 허브를 hive.metastore.warehouse.dir 에서 변경할수 있다. Internal table(Managed table)들을 drop하게 되면, 모든 메타데이터와 테이블 데이터들이 hdfs에서 영구적으로 삭제된다. ..." }, { "title": "Kafka Streams", "url": "/posts/kafka-streams/", "categories": "DataEngineering, Kafka", "tags": "", "date": "2021-01-20 18:09:00 +0800", "snippet": "Kafka Streams Kafka Streams API로 Java Application 개발 가능Stream ConceptsStreamunbounded(unknown, unlimited size), 지속적으로 업데이트 되는 데이터 셋을 말한다. 카프카 토픽처럼 하나이상의 stream partition으로 구성된다.stream partition 이란 ordered,replayable, fault-tolerant한 변경불가능한 data record들의 순서이다. data record 는 key-value 쌍으로 정의된다.Str..." }, { "title": "Kubernetes Compute Resources", "url": "/posts/kubernetes-compute-resources/", "categories": "Kubernetes", "tags": "", "date": "2021-01-16 20:50:00 +0800", "snippet": "Kubernetes 에서는 두가지 리소스 타입이 있다. Compute resources(CPU, memory) API resources(k8s objects - pods, services ) CPU 단위 : m (1/1000 core) Memory 단위 : E,P,T,G,M,K or Ei,Pi,Ti,Gi,Mi,KiQuality of Source(QoS)kubernetes는 resource request와 limit이 존재하여 pod container가 소모하는 리소스의 양을 조절할수 있게 해준다.Resource req..." }, { "title": "kubelet", "url": "/posts/kubelet/", "categories": "Kubernetes", "tags": "", "date": "2021-01-16 19:39:00 +0800", "snippet": "kubelet각각의 노드에서 동작하는 “node agent”" }, { "title": "Probe", "url": "/posts/probe/", "categories": "Kubernetes", "tags": "", "date": "2021-01-16 19:36:00 +0800", "snippet": "Container probesProbe는 kubelet에 의해서 주기적으로 컨테이너에 수행되는 diagnostic이다. diagnostic을 수행하기위해서 kubelet은 컨테이너에 의해 구현된 handler를 호출한다. ExecAction : 컨테이너내의 특정 커멘드를 실행한다. TCPSocketAction : pod의 ip 주소의 특정 포트에 TCP 체크를 수행한다. HTTPGetAction : 특정 ip 주소에 특정 포트에 대한 HTTP Get 요청을 수행한다.probe는 3가지 결과를 가질수 있다. Success..." }, { "title": "Pods", "url": "/posts/pods/", "categories": "Kubernetes", "tags": "", "date": "2021-01-16 15:14:00 +0800", "snippet": "PodsKubernetes에서 생성가능하고 관리할수 있는 가장 작은 deployable units of computingPod은 컨테이너들을 실행하기 위한 명세, 네트워크 자원, 공유 저장공간을 가진 하나이상의 컨테이너 그룹Pod의 컨텐츠들은 항상 같은 공간에 위치해 있고, 함께 스케줄되며 공유된 컨텍스트로 실행된다.Pod이란?도커 개념으로 설명하자면, Pod은 공유된 namespace와 filesystem 저장공간을 가진 도커 컨테이너 그룹쿠버네티스에서 Pod은 주로 두가지 방법으로 사용된다. single container..." }, { "title": "Kubectl", "url": "/posts/kubectl/", "categories": "Kubernetes", "tags": "", "date": "2021-01-15 15:36:00 +0800", "snippet": "Kubectl 개요Kubectl은 쿠버네티스 클러스터를 제어하기 위한 커맨드 라인 도구이다." }, { "title": "SCDF", "url": "/posts/scdf/", "categories": "DataEngineering, SCDF", "tags": "", "date": "2021-01-12 12:49:00 +0800", "snippet": "SCDF(Spring Cloud Data Flow)기능 스트림, 태스크 제공 태스크 실행: 단일, 여러개를 묵은 Composed 태스크 스타터앱 기존 스프링 배치 어플리케이션 이관 가능Scalability Kubernates 에서 운영가능 파이프라인 어플리케이션은 하나의 포드로 구동 스트림에서 특정 어플리케이션을 지목하여 포드를 수평.수직 확장 가능" }, { "title": "Rollup Jobs", "url": "/posts/rollup-jobs/", "categories": "Database, Elasticsearch", "tags": "", "date": "2021-01-11 21:23:00 +0800", "snippet": "Rollup Jobsrollup job이란 인덱스 패턴에의해 명시된 인덱스들의 데이터를 집계하여 새로운 인덱스에 저장하는 주기적인 task를 말한다. Rollup 인덱스들은 시각화와 리포트 생성을 위해서 수개월, 수년의 historical data들을 compact하게 저장하기위한 좋은 방법이다.현재는 X-Pack에있는 기능이다." }, { "title": "mac에서right command를 한영전환키로 바꾸기", "url": "/posts/mac%EC%97%90%EC%84%9Cright-command%EB%A5%BC-%ED%95%9C%EC%98%81%EC%A0%84%ED%99%98%ED%82%A4%EB%A1%9C-%EB%B0%94%EA%BE%B8%EA%B8%B0/", "categories": "Settings", "tags": "", "date": "2021-01-09 11:22:00 +0800", "snippet": "https://tomou-kr.tistory.com/entry/%EB%A7%A5%EB%B6%81-%EC%98%A4%EB%A5%B8%EC%AA%BD-Command%ED%82%A4%EB%A5%BC-%ED%95%9C%EC%98%81%ED%82%A4%EB%A1%9C-%EC%A0%84%ED%99%98%ED%95%98%EA%B8%B0-Karabiner" }, { "title": "Builder Design Pattern", "url": "/posts/builder-design-pattern/", "categories": "SoftwareEngineering", "tags": "", "date": "2021-01-08 21:04:00 +0800", "snippet": "Builder Design Pattern상대적으로 복잡한 객체생성을 다루는 패턴중 하나또다른 객체를 사용하여 객체를 생성하기 위한 객체화 과정을 분리Examplepublic class BankAccount { private String name; private String accountNumber; private String email; private boolean newsletter; // constructors/getters public static class BankAccou..." }, { "title": "Logical Replication", "url": "/posts/logical-replication/", "categories": "Database, PostgreSQL", "tags": "", "date": "2021-01-06 22:11:00 +0800", "snippet": "Logical Replicationreplication identity(보통은 primary key) 에 기반하여, 데이터 오브젝트들과 그것들의 변화를 복제하는 방식을 말한다. 정확한 block 주소, byte-by-byte replication을 사용하는 physical replication과는 비교되는 개념이다. PostgreSQL은 physical,logical replication 둘다를 병렬적으로 지원한다. Logical replication은 data replication과 보안에 높은 수준의 통제를 허락한다.Log..." }, { "title": "Replica Identity", "url": "/posts/postgresql/", "categories": "Database, PostgreSQL", "tags": "", "date": "2021-01-06 10:02:00 +0800", "snippet": "Replica Identity이 세팅에 따라서 업데이트 또는 삭제된 행들을 파악하는데 사용되는 WAL(write-ahead-log)에 기록되는 정보가 달라진다. logical replication이 사용중일때를 제외하고는 효력이 없다.4가지 모드 DEFAULT non system table들에 default 모드 pk 칼럼들의 이전값을 WAL에 기록 USING INDEX named index에 의해 커버된 칼..." }, { "title": "Thread Safety", "url": "/posts/thread-safety/", "categories": "OS", "tags": "", "date": "2021-01-06 09:02:00 +0800", "snippet": "Thread safety는 멀티스레드 코드에서 적용가능한 컴퓨터 프로그래밍 컨셉이다. thread safe code는 모든 스레드들이 적절하게 동작하고 의도치않은 상호작용없이 디자인 명세를 만족하는 방식으로 공유된 자료구조들을 조작한다.출처https://en.wikipedia.org/wiki/Thread_safety" }, { "title": "git commands", "url": "/posts/git-commands/", "categories": "Git", "tags": "", "date": "2021-01-04 21:42:00 +0800", "snippet": "global username, email 설정$ git config — global user.name “Igor Santos”$ git config — global user.email “igor.santos@example.com”직전 commit의 committer name, email 변경git commit --amend --author=&quot;[NAME] &amp;lt;EMAIL&amp;gt;&quot;" }, { "title": "git cherry pick 쉽게 하기", "url": "/posts/git-cherry-pick-%EC%89%BD%EA%B2%8C-%ED%95%98%EA%B8%B0/", "categories": "Git", "tags": "", "date": "2021-01-04 21:35:00 +0800", "snippet": "다른 브랜치에 있는 특정 커밋을 현재 브랜치로 커밋하고 싶을때 보통 다음과 같이 사용한다.git cherry-pick 586030a0c492491b89768436a5ef2d821c6176e6visual studio code의 plugin인 GitLens를 사용하면 아래와같이 손쉽게 cherry picking할수 있다.출처https://dev.to/iamafro/how-to-merge-a-specific-commit-into-another-branch–oak" }, { "title": "Flume", "url": "/posts/flume/", "categories": "DataEngineering, Hadoop", "tags": "", "date": "2021-01-03 14:52:00 +0800", "snippet": "Flume Hadoop과 함께 개발 Built-in sinks for HDFS and HBase 원래는 log aggregation을 다루기 위해 만들어짐 Data와 하둡클러스터 사이의 bufferComponents of an agent Source 데이터가 들어오는 장소 선택적으로 channel selector 와 interceptor들을 가질수 있음 Channel 데이터가 어떻게 전달되는지 (메모리 또는 파일을 통해서) Si..." }, { "title": "예전에 사용되던 시스템들", "url": "/posts/%EC%98%88%EC%A0%84%EC%97%90-%EC%82%AC%EC%9A%A9%EB%90%98%EB%8D%98-%EC%8B%9C%EC%8A%A4%ED%85%9C%EB%93%A4/", "categories": "DataEngineering, Hadoop", "tags": "", "date": "2021-01-03 13:07:00 +0800", "snippet": "예전에 사용되던 시스템들Ganglia Distributed monitoring system UC 버클리에 의해서 개발됨 원래 대학교들에 의해서 사용됨 Wikimedia/Wikipedia가 예전에 사용 Ambari/Cloudera Manager/Grafana에 의해서 대체됨Chukwa 하둡클러스터의 로그들을 수집하고 분석하기 위한 시스템 예전에 넷플릭스에 의해서 채택되었음 현재는 Flume, Kafka에 의해서 대체됨 위 도구들이 더 범용적 더 빠름..." }, { "title": "Hue", "url": "/posts/hue/", "categories": "DataEngineering, Hadoop", "tags": "", "date": "2021-01-03 12:31:00 +0800", "snippet": "Hue (Hadoop User Experience) Hortonworks Ambari는 관리,쿼리 issuing,파일 UI제공 Zeppelin은 notebook 제공 Cloudera Hue는 쿼리 issuing,파일 UI 그리고 notebook 제공 Cloudera Manager가 관리에 사용됨 Hue 는 Cloudera의 Ambari와 유사" }, { "title": "Zeppelin", "url": "/posts/zeppelin/", "categories": "DataEngineering, Hadoop", "tags": "", "date": "2021-01-03 10:33:00 +0800", "snippet": "ZeppelinApache Spark Integration Spark shell에 에서 할수 있는것처럼 Spark code를 interactively 실행가능 development cycle을 빠르게함 빅데이터를 대상으로 쉽게 실험하고 탐험할수 있게 해줌 SparkSQL에 직접적으로 SQL쿼리들을 실행가능 쿼리결과들이 chart,graph로 시각화될수 있음 Spark를 data science tool처럼 느끼도록 만듬" }, { "title": "[NAVER DEVIEW 2020] Bye Oracle, Hello PG : 쇼핑검색플랫폼, MSA로 새옷을 갈아입다 정리", "url": "/posts/naver-deview-2020-bye-oracle-hello-pg-%EC%87%BC%ED%95%91%EA%B2%80%EC%83%89%ED%94%8C%EB%9E%AB%ED%8F%BC-msa%EB%A1%9C-%EC%83%88%EC%98%B7%EC%9D%84-%EA%B0%88%EC%95%84%EC%9E%85%EB%8B%A4-%EC%A0%95%EB%A6%AC/", "categories": "Conference", "tags": "", "date": "2021-01-02 14:51:00 +0800", "snippet": "[NAVER DEVIEW 2020] “Bye Oracle, Hello PG: 쇼핑검색플랫폼, MSA로 새옷을 갈아입다.” 정리기존의 문제점 오라클 데이터베이스가 Single Point Of Failure 오라클 데이터베이스의 scale up 비용증가 오라클 데이터베이스의 부하증가 PostgreSQL가 Oracle에 비해 좋은점 Distributed Database CDC 파이프라인 구성 용이 CITUS CITUS는 postgres에 대한 extention ..." }, { "title": "Write-ahead logging", "url": "/posts/write-ahead-logging/", "categories": "Database, Theory", "tags": "", "date": "2021-01-02 10:02:00 +0800", "snippet": "Write-ahead logging컴퓨터과학에서 write-ahead logging(WAL) 은 데이터베이스 시스템에서 atomicity와 durability를 제공하기위한 기술중 하나이다. 변경정보가 로그로 먼저 기록되고, Stable Storage에 반드시 기록되어야하고 그리고 데이터베이스에 기록된다. Stable Storage란 write연산에 대한 원자성을 보장하는 데이터 스토리지 기술의 분류이다.WAL을 사용하는 시스템에서는, 모든 수정사항들은 log로 쓰여진다음에 적용되다. 보통 redo와 undo정보는 로그에 저..." }, { "title": "JAR", "url": "/posts/jar/", "categories": "Java", "tags": "", "date": "2020-12-30 20:36:00 +0800", "snippet": "JAR(Java ARchive) 여러 Java Class 파일들과 그와 연관된 metadata와 resources(text,images,etc)를 배포를 위해 하나의 파일로 모으기 위해 사용되는 패키지 파일 포맷JAR파일들은 Java-specific한 manifest file를 포함하는 압축파일이다. 보통 jar 파일 익스텐션을 갖고 있다. manifiest file이란 하나의 단위를 구성하는 여러 파일그룹에 대한 metadata를 포함하는 파일을 말함.디자인JAR 파일은 Java runtimes가 효율적으로 전체 애플리케..." }, { "title": "Intellij shortcut", "url": "/posts/intellij-shortcut/", "categories": "Shortcut", "tags": "", "date": "2020-12-30 13:07:00 +0800", "snippet": " 동작 커멘드 reformat code Option+Cmd+L finding file Cmd+Shift+O " }, { "title": "Oozie", "url": "/posts/oozie/", "categories": "DataEngineering, Hadoop", "tags": "", "date": "2020-12-27 22:35:00 +0800", "snippet": "Oozie 하둡테스크들을 스케줄링및 실행하는 시스템workflow 설정 단계 각각의 단계가 독립적으로 잘 동작하는지 확인 잡에대하여, HDFS에 디렉토리를 생성 workflow.xml파일 생성 및 HDFS폴더에 두기 workflow.xml이 필요한 변수정보들을 정의하는 job.properties를 생성하기 잡을 실행하고자하는 로컬 파일 시스템에 생성 properties를 xml내에서도 생성가능 Oozie Coordinators Workflow 실행을 스케줄링 시간과 빈도에 따라서..." }, { "title": "Zookeeper", "url": "/posts/zookeeper/", "categories": "DataEngineering, Hadoop", "tags": "", "date": "2020-12-27 18:18:00 +0800", "snippet": "Zookeeper 클러스터내에서 동기화되어야하는 정보들을 기록 어느 노드가 마스터인가? 작업들이 어느 워커에 할당되어있는가? 현재 이용가능한 워커는 무엇인가? 클러스터내에 partial failure를 회복시키기 위해 사용가능 HBase, High-Availability MapReduce, Drill, Storm 등을 통합시킬수 있는 부분Failure modes 마스터 노드가 크래시 되면, 워커노드중에 마스터노드를 선출해야함 워커노드가 크래시되면, ..." }, { "title": "YARN,MESOS,TEZ", "url": "/posts/yarn/", "categories": "Hadoop", "tags": "", "date": "2020-12-27 15:42:00 +0800", "snippet": "YARN YARN은 클러스터에 컴퓨팅 리소스들을 관리하고, HDFS는 클러스터의 리소스 저장공간을 관리아키텍처동작방식 어플리케이션이 클러스터에 작업을 분배하기 위해서 Resouce Manager와 통신 데이터 로컬리티를 명시함 - 어느 HDFS블럭(들)을 처리하고자 하는가? YARN은 HDFS블럭들을 갖고있는 노드에서 처리하려고 노력함 어플리케이션에 대해서 다른 스케줄링 옵션 명시가능 클러스터에 즉시 하나이상의 어플리케이션 실행가능 Scheduling Type ..." }, { "title": "CDH vs HDP", "url": "/posts/cdh-vs-hdp/", "categories": "DataEngineering, Hadoop", "tags": "", "date": "2020-12-27 10:29:00 +0800", "snippet": "CDH vs HDP CDH : Cloudera Hadoop Distribution HDP : Hortonworks Data PlatformCloudera(CDH를 만든회사) 와 Hortonworks(HDP를 만든회사)가 합병을 하여 현재 Cloudera로 불리고 있다.합병된이후로 Cloudera Data Platform (CDP)가 출시 되었다.CDH,HDP가 여전히 존재하지만, 새로운 유저들은 CDP로 가야한다. 개발이 집중될 부분이 CDP이기 때문이다.출처https://stackoverflow.com/questions/..." }, { "title": "Hadoop Query Engine", "url": "/posts/hadoop-query-engine/", "categories": "DataEngineering, Hadoop", "tags": "", "date": "2020-12-26 22:37:00 +0800", "snippet": "Query EngineApache Drill 비관계형 디비(또는 파일스토어)를 위한 SQL쿼리 엔진 Hive, MongoDB,HBase flat JSON or HDFS상의 Parquet 파일, S3, Azure, 구글 클라우드, 로컬 파일 시스템 구글 Dremel에 기반 거의 SQL Phoneix 트랜젝션을 지원하는 HBase SQL Driver 빠르고, low-latency - OLTP ..." }, { "title": "Trouble Shooting", "url": "/posts/trouble-shooting/", "categories": "DataEngineering, Spark", "tags": "", "date": "2020-12-26 19:15:00 +0800", "snippet": "’&#39;’spark-submit –packages org.mongodb.spark:mongo-spark-connector_2.11:2.0.0 MongoSpark.py’’’ 실행시에러’’’java.lang.NoSuchMethodError: org.apache.spark.sql.catalyst.analysis.TypeCoercion$.findTightestCommonTypeOfTwo()Lscala/Function2;‘’’해결방법spark-submit --packages org.mongodb.spark:mongo-spark-co..." }, { "title": "Kafka configuration 정리", "url": "/posts/kafka-configuration-%EC%A0%95%EB%A6%AC/", "categories": "DataEngineering, Kafka", "tags": "", "date": "2020-12-26 16:06:00 +0800", "snippet": " config 설명 auto.offset.reset latest : 가장 마지막 offset부터, earliest : 가장 처음 offset부터, none : 해당 consumer group이 가져가고자 하는 topic의 consumer offset정보가 없으면 exception 발생시킴 max.poll.records 단일 호출 poll()에 대해 최대 레코드 수를 조정. delete.retention.m..." }, { "title": "Kafka api정리", "url": "/posts/kafka-api%EC%A0%95%EB%A6%AC/", "categories": "DataEngineering, Kafka", "tags": "", "date": "2020-12-26 16:02:00 +0800", "snippet": "API정리 api 설명 KafkaConsumer.poll(Duration) broker에 데이터를 가져오도록 요청하고 나서 duration timeout이 날때까지 데이터가 브로커로부터 가져오지 못하면 즉시 빈 collection을 반환한다. " }, { "title": "Gitflow", "url": "/posts/gitflow/", "categories": "Git", "tags": "", "date": "2020-12-23 09:37:00 +0800", "snippet": "참고링크https://woowabros.github.io/experience/2017/10/30/baemin-mobile-git-branch-strategy.html" }, { "title": "StreamSQL", "url": "/posts/streamsql/", "categories": "DataEngineering, Kafka", "tags": "", "date": "2020-12-21 21:33:00 +0800", "snippet": "StreamSQL실시간 데이터 스트림을 처리가 가능한 SQL을 확장한 쿼리 언어이다. SQL은 주로 테이블을 다루는 용도이지만, StreamSQL은 스트리밍 데이터를 처리하는 능력까지 갖고있다. 스트림 데이터에대한 쿼리는 지속적으로 증가하는 결과값이 리턴된다.세부적인 연산들 SELECT - 스트림에 있는 데이터를 대상으로 함수를 계산하거나 원치않는 튜플들을 걸러낼수 있음. JOIN - 테이블과 스트림데이터를 조인하는 기능. UNION,MERGE - 두개이상의 스트림 데이터를 대상으로 합집합 또..." }, { "title": "MongoDB Overview", "url": "/posts/mongodb-overview/", "categories": "Database, MongoDB", "tags": "", "date": "2020-12-20 12:07:00 +0800", "snippet": "용어 Databases Collections : rdb에서 행과 같은 개념 Documents : rdb에서 열과 같은 개념 Replication Sets Single Master구조 프라이머리 노드의 데이터 베이스 인스턴스 사본을 백업 세컨더리 노드들은 프라이머리 노드가 다운되면 몇초내에 새로운 프라이머리 노드를 선출가능 프라이머리 노드가 다운됬을때,오퍼레이션 로그가 가용공간을 넘어서는 경우에는 해당 노드를..." }, { "title": "CAP이론", "url": "/posts/cap%EC%9D%B4%EB%A1%A0/", "categories": "Database, Theory", "tags": "", "date": "2020-12-19 21:51:00 +0800", "snippet": "분산 데이터 스토어는 다음 세가지 성질중 2가지 이상을 모두 만족할수는 없다는 이론 Consistency : 모든 읽기쿼리는 가장 최근에 변경된 데이터를 읽거나 만약 읽을수 없다면 에러를 수신해야함. Availability : 모든 요청은 에러를 수신해서는 안되며, 대신 가장 최근에 변경된 데이터를 읽으리라는 보장은 할수 없다. Partition tolerance : 분산시스템에서의 노드들 간에 네트워크에서 메시지가 딜레이되거나 유실됨에도 불구하고 시스템은 계속해서 동작해야한다. 네트워크 파..." }, { "title": "OLTP,OLAP", "url": "/posts/oltpolap/", "categories": "DataEngineering, Concept", "tags": "", "date": "2020-12-17 10:10:00 +0800", "snippet": "Online Transaction Processing(OLTP) 디비에 트랜젝션 데이터를 캡쳐,가공,저장 banking and credit card activity or retail checkout scanning에 사용됨 CRUD가 자주 발생해도 빠르게 처리할수 있어야함 Online Analytical Processing(OLAP) 데이터 마이닝, 애널리틱스, 비즈니스 인텔리전스 프로젝트를 하기위해 오래된 데이터를 대상으로 복잡한 쿼리를 사용 복잡한 쿼리에 대한 응답시..." }, { "title": "Hive와Impala", "url": "/posts/hive%EC%99%80impala/", "categories": "DataEngineering, Hadoop", "tags": "", "date": "2020-12-16 22:42:00 +0800", "snippet": "Hive와 Impala에 대한 소개Hive와 Impala는 하둡시스템으로부터 데이터를 추출하기 위해서 SQL과 유사한 인터페이스를 제공하는 툴이다.Impala vs Hive Impala Hive Google의 Dremel project에 의해 영감을 받아서 2012년 Cloudera에 의해서 개발 Facebook에 의해서 2017년 개발 Impala SQL을 사용하며 밀리세컨트 단위의 낮은 쿼리 latency 보장 HiveQL을..." }, { "title": "Adhoc Query", "url": "/posts/adhoc-query/", "categories": "Database, Theory", "tags": "", "date": "2020-12-16 22:27:00 +0800", "snippet": "Adhoc쿼리란 코드가 실행될때마다 변경되는 쿼리를 말한다.다음의 코드 예를 보자.var newSqlQuery = &quot;SELECT * FROM table WHERE id = &quot; + myId;위 코드를 보면 myId의 값에 따라서 쿼리문이 변경됨을 알수있다.ad hoc query의 반대로는 Stored Procedure같은 predefined query가 있다." }, { "title": "Apache Pig", "url": "/posts/pig/", "categories": "DataEngineering, Hadoop", "tags": "", "date": "2020-12-16 19:50:00 +0800", "snippet": "Why Pig? mapper와 reducer를 작성하는것은 시간이 많이 걸림. Pig는 Pig Latin이라는 scripting 언어를 도입하여 SQL과 유사한 문법으로 map,reduce 스탭을 정의할수 있게한다. pig와 mapReduce를 혼용할수도 있다. " }, { "title": "Elastic Stack", "url": "/posts/elastic-stack/", "categories": "Database, Elasticsearch", "tags": "", "date": "2020-12-16 10:07:00 +0800", "snippet": "Elastic Stack KIBANA BEATS LOGSTASH X-PACK ELASTICSEARCHKibana analytics &amp;amp; visualization platform elastic search 데시보드, pie chart, line chart등을 생성가능 실시간 웹사이트 트래픽 모니터링 가능 이상 현상 감지, 데이터 예측 가능 es의 웹 인터페이스 Logstash 원래는 log를 처리하고 es에 보내는 용도로 사용됨 ..." }, { "title": "Elastic Search Overview", "url": "/posts/elastic-search-overview/", "categories": "Database, Elasticsearch", "tags": "", "date": "2020-12-16 09:56:00 +0800", "snippet": "Elasticsearch use case 검색엔진 구현 Application Performance Management(APM) : 어플리케이션 로그, 시스템 통계정보 분석(error, CPU/memeory usage) 대용량 데이터 분석 Anomality Detection 특징 데이터는 document로 저장됨(relational database의 row와 유사함) document는 field로 구성(relational db의 column과 유사) ..." }, { "title": "Spark", "url": "/posts/spark/", "categories": "DataEngineering, Spark", "tags": "", "date": "2020-12-15 21:02:00 +0800", "snippet": "Spark란? large-scale data processing을 위한 빠르고 범용적인 엔진Spark의 특징 machine learning, data mining, graph analysis, streaming data 하는데 사용 Scalable memory based solution이기때문에 disk based solution 보다 빠르다. momory에서 동작하면 Hadoop MapReduce보다 100배가량까지 빠르고, disk에서 동작하면 10배까지 빠르다. ..." }, { "title": "Trouble Shooting", "url": "/posts/trouble-shooting/", "categories": "DataEngineering, Hadoop", "tags": "", "date": "2020-12-15 15:53:00 +0800", "snippet": " 에러로그 대처방법 pip install mrjob==0.5.11시 다음 에러가 발생 - Command &quot;python setup.py egg_info&quot; failed with error code 1 in /tmp/pip-build-AF7G__/setuptools/ pip install --upgrade pip 후 재설치 " }, { "title": "vs code 단축키,", "url": "/posts/vs-code-%EB%8B%A8%EC%B6%95%ED%82%A4/", "categories": "Settings", "tags": "", "date": "2020-12-15 14:17:00 +0800", "snippet": " 설명 커멘드 json 포맷으로 정렬 Cmd + K + F " }, { "title": "MapReduce", "url": "/posts/mapreduce/", "categories": "DataEngineering, Hadoop", "tags": "", "date": "2020-12-15 12:44:00 +0800", "snippet": "MapReduce데이터를 두가지 단계로 처리한다 : map phase, reduce phase.map phase에는 HDFS로 부터 데이터를 읽는다. 각각의 dataset은 input record라고 부른다.reduce phase에는 실제 계산이 수행되고 결과가 저장된다. 그리고 저장 타깃은 database,HDFS 등이 될수 있습니다.mapper와 reducer들은 클러스터에서 병렬적으로 실행된다.동작방식map phase 도중, key-value pair를 생성하여 reducer에 전달하고, reducer에서 key로 소팅..." }, { "title": "HDFS", "url": "/posts/hdfs/", "categories": "DataEngineering, Hadoop", "tags": "", "date": "2020-12-15 11:09:00 +0800", "snippet": "HDFS(The Hadoop Distributed File System) 데이터가 전체 클러스터에 분산되어 저장되도록 함 데이터에 빠르게 접근하고 분석하도록 함 대용량의 파일들을 여러 블럭으로 쪼갬, Hadoop 2.0의 경우, block당 default 128MB. 여러 컴퓨터에 데이터를 분산시키고 병렬로 처리가능 여러 컴퓨터에 동일 데이터 블럭이 백업용으로 저장되어있음. HDFS Architecture Name Node, Data Node로 나누어짐. ..." }, { "title": "Hadoop Overview", "url": "/posts/hadoop/", "categories": "DataEngineering, Hadoop", "tags": "", "date": "2020-12-15 10:17:00 +0800", "snippet": "왜 하둡을 쓰는가? 빅데이터 처리가능 - eg. 하루에 terabyte Horizontal scaling으로 계속 성능을 linear하게 향상가능 Disk seek time 감소 Hardware failure에 대해 유연함 Processing times이 단일 노드에 비해 빠름(병렬처리) Vertical scaling으로는 위의 장점을 얻는것이 불가능하다. ..." }, { "title": "Image", "url": "/posts/image/", "categories": "Docker", "tags": "", "date": "2020-12-13 15:10:00 +0800", "snippet": " App Binaries와 dependencies image data에 대한 Metadata와 image를 실행하는 방법 공식 정의 : root filesystem의 변화에대한 정렬된 컬렉션과 런타임에 컨테이너내에서 실행되기 위해 대응되는 execution parameter들 complete os, kernel, kernel modules가 아니다. image들은 file system변화, 메타데이터로 구성됨 여러 layer로 구성되며, 각각의 layer는 host에 한번만 저장된다. (컨테이너 별로 각각 생성되지..." }, { "title": "Docker Network", "url": "/posts/docker-network/", "categories": "Docker", "tags": "", "date": "2020-12-13 12:39:00 +0800", "snippet": " 도커내에있는 컨테이너들은 bridge 네트워크에 연결되어있음. 컨테이너들은 서로 커뮤니케이션 가능 하나의 호스트의 포트번호에는 도커 컨테이너 포트번호는 하나와 매칭 컨테이너들은 inter-communication을 위해서 서로서로의 ip에 의존해서는 안된다. custom network를 사용한다면 DNS가 built in 되어있음." }, { "title": "nginx", "url": "/posts/nginx/", "categories": "Web", "tags": "", "date": "2020-12-12 22:15:00 +0800", "snippet": "NGINX란?더 적은 자원으로 더 빠르게 데이터를 서비스할수있는 웹서버Web Server HTTP 프로토콜에 따라서 서버쪽에서 정보를 제공하는 소프트웨어. 대표적으로 Apache가 있다.출처https://opentutorials.org/module/384/3462" }, { "title": "Kafka Stream vs Spark Streaming", "url": "/posts/kafka-stream-vs-spark-streaming/", "categories": "DataEngineering, Concept", "tags": "", "date": "2020-12-12 22:15:00 +0800", "snippet": "Apache Kafka StreamKafka에 저장된 데이터를 처리하고 분석하기 위한 클라이언트 라이브러리데이터를 처리하는 방법 2가지 Kafka -&amp;gt; Kafka : Kafka Stream이 aggregations, filtering 등 작업을 처리하고 데이터를 Kafka에 보낸다. 설정이 잘 되어있다면, scalability, high availability, high throughput등을 달성할수 있다. Kafka -&amp;gt; External Systems(Database,Spark..." }, { "title": "Framework vs Library", "url": "/posts/framework-vs-library/", "categories": "SoftwareEngineering", "tags": "", "date": "2020-12-12 22:14:00 +0800", "snippet": " Framework Library 제어를 역전시킨다. 즉, 개발자에게 어떻게 구현할지를 강요한다. 라이브러리는 프로그래머가 필요할때, 필요한장소에서 라이브러리를 호출한다. " }, { "title": "Batch Stream vs Stream Processing", "url": "/posts/batch-stream-vs-stream-processing/", "categories": "DataEngineering, Concept", "tags": "", "date": "2020-12-12 22:12:00 +0800", "snippet": "Batch Processing vs Stream Processing Batch processing Stream processing 데이터가 특정 시간동안 수집됨 데이터가 계속 수집됨 데이터가 모두 수집되고 나서 처리됨 데이터가 실시간으로 처리됨 기본적으로 시간이 많이 걸리고,실시간으로 처리할 필요가없는 대용량 데이터에 적합 실시간으로 데이터를 처리하고 즉시 사용되어야하는 경우에 적합 " }, { "title": "객체를 여러개 주입하고 싶을때", "url": "/posts/%EA%B0%9D%EC%B2%B4%EB%A5%BC-%EC%97%AC%EB%9F%AC%EA%B0%9C-%EC%A3%BC%EC%9E%85%ED%95%98%EA%B3%A0-%EC%8B%B6%EC%9D%84%EB%95%8C/", "categories": "Spring", "tags": "", "date": "2020-12-12 22:11:00 +0800", "snippet": "여러 객체중에 특정 객체만 주입하기스프링에서 interface를 구현한 객체가 여러개 있는경우 충돌이 발생할수 있다.이와 같은경우 다음과 같이 해결가능하다.해결방법충돌이 나는 클래스 둘중에 하나에 @Primary annotation을 정의한다.@Primary@Componentpublic class MyBcryptPasswordEncoder implements PasswordEncoder { ...}위와 같이 정의해놓으면, 단독으로 주입을 할경우 충돌을 해결할수 있다.여러 객체를 주입하기@Autowiredprivate Ma..." }, { "title": "Apache Avro", "url": "/posts/apache-avro/", "categories": "DataEngineering, Concept", "tags": "", "date": "2020-12-12 22:11:00 +0800", "snippet": "데이터 교환 방식 JSON, XML 모든 필드 네임이 반복되므로 용량이 많이 차지하게 된다. 파싱될때 퍼포먼스가 느리다. 데이터에 스키마가 존재하지만 스키마정보는 데이터에 존재하지 않는다. 다른 시스템에서 스키마를 수정하면 그 시스템에 의존하는 모든 프로세스에서 코드를 변경해야한다. Avro, Protocol Buffers, Thrift 데이터 직렬화 시스템 스키마가 데이터에 함께 저장된다. 다른 시스템에서 스키마를 수정해면 변경사항이 ..." }, { "title": "lombok", "url": "/posts/lombok/", "categories": "Spring", "tags": "", "date": "2020-12-12 22:10:00 +0800", "snippet": "Lombok장점 boilerplate code를 작성하는데 드는 시간.비용 절감 코드가 깔끔해진다. @Datapublic class MyCandlestick { private double high; private double low; private double open; private double close; private double volume; private long date;}@Data annotation을 사용함으로서, 모든 필드에 getter,setter를 추가..." }, { "title": "Bean", "url": "/posts/bean/", "categories": "Spring", "tags": "", "date": "2020-12-12 22:10:00 +0800", "snippet": "Bean이란?IoC 컨테이너에 의해서 생성되고 조립되고, 관리되는 오브젝트Spring Bean 구성요소 class : Bean으로 등록할 java 클래스 id : Bean의 고유 식별자 scope : Bean을 생성하기 위한 방법(singleton, prototype 등) constructor-arg : Bean 생성시 생성자에 저달할 파라미터 property : Bean 생서 시 setter에 전달할 인수 개발자가 직접 제어가 불가능한 외부 라이브러리 또는 설정을 위한 클래스를 Bean으로 등록할 때 @Bean 어..." }, { "title": "annotation", "url": "/posts/annotation/", "categories": "Spring", "tags": "", "date": "2020-12-12 22:09:00 +0800", "snippet": "@Configuration해당 클래스에서 1개이상의 Bean을 생성하고 있음을 명시 @Bean 어노테이션을 사용하는 클래스의 경우 반드시 @Configuration과 함께 사용해주어야 함.만약 그렇지않으면, 생성된 객체가 싱글톤을 보장받지 못한다.@Component직접 개발한 클래스를 Bean으로 등록하고자 하는 경우에 사용@Target이 TYPE로 지정되어 Class위에서만 선언될수 있다.@ContextConfigurationintegration test를 위해, ApplicationContext를 어떻게 load하고 con..." }, { "title": "MSA", "url": "/posts/msa/", "categories": "SoftwareEngineering", "tags": "", "date": "2020-12-12 22:08:00 +0800", "snippet": "MSA의 등장배경Monolithic Architecture 소프트웨어의 모든 요소가 한 프로젝트에 통합되어있는 형태. 소규모 프로젝트에 적합 한계점 서비스/프로젝트가 커질수록, 영향도 파악 및 전체 시스템 구조의 파악에 어려움이 있음. 빌드 시간 및 테스트시간, 배포시간이 기하급수적으로 증가 서비스를 부분적으로 scale-out하기 힘듬 부분의 장애가 전체 서비스의 장애로 이어지는 경우 발생 Micro Service Architecture 하나의 ..." }, { "title": "Monorepo", "url": "/posts/monorepo/", "categories": "SoftwareEngineering", "tags": "", "date": "2020-12-12 22:08:00 +0800", "snippet": "Monorepo 란?vcs에서 같은 repository에 여러 프로젝트들이 모여있는 소프트웨어 개발 전략장점 코드 재사용이 쉬움 - 다른 개발자의 코드를 볼 수 있기 때문에, 코드 재사용이 쉽다. 빌드 최적화 - 여러 프로젝트들이 third-party dependency에 의존하고 있을때, 그 dependency가 여러번 다운로드 되고, 빌드 될수있다. monorepo 에서는 참조된 의존성들이 같은 코드베이스에 존재하므로 빌드가 쉽게 최적화 될수있다. 의존성 관리가 편해짐프로젝트들이 독립된 r..." }, { "title": "Convention over configuration", "url": "/posts/convention-over-configuration/", "categories": "SoftwareEngineering", "tags": "", "date": "2020-12-12 22:07:00 +0800", "snippet": "Convention over configuration프레임워크를 사용하는 개발자가 결정해야하는 것들을 flexibility감소 없이 감소시키는것.예를들면, Sales라는 클래스가 model에 존재하고, 그 클래스에 대응하는 table은 기본적으로 “Sales”라고 불리는데, 오직 이러한 convention에 벗어날때만 (product sales같은) 개발자가 이름을 변경하는 코드를 작성하게 하는것." }, { "title": "intellij vmoption setting", "url": "/posts/intellij-vmoption-setting/", "categories": "Settings", "tags": "", "date": "2020-12-12 22:06:00 +0800", "snippet": "Windows{intellij path}/bin/idea64.exe.vmoptions 파일에 다음 추가 (메모리는 시스템 상황에 맞게 - 구동 속도 향상)MACHelp -&amp;gt; Edit Custom VM Options..." }, { "title": "build setting", "url": "/posts/build-setting/", "categories": "gradle", "tags": "", "date": "2020-12-12 22:05:00 +0800", "snippet": "api 와 implementation 차이점 api: 의존 라이브러리 수정시 본 모듈을 의존하고 있는 모듈들 또한 재빌드A(api) &amp;lt;- B &amp;lt;- C 의 경우 C 에서 A 를 접근할 수 있음A 수정시 B 와 C 모두 재빌드 implementaion: 의존 라이브러리 수정시 본 모듈까지만 재빌드A(implementation) &amp;lt;- B compile과 implementation 차이점 compile implementaion ..." }, { "title": "Kafka Trouble Shooting", "url": "/posts/kafka-trouble-shooting/", "categories": "DataEngineering, Kafka", "tags": "", "date": "2020-12-04 22:35:00 +0800", "snippet": "The process cannot access the file because it is being used by another process.위 경우는 다른 카프카가 이미 해당 파일을 사용하고 있기 때문에 발생한다. 가장 빠른 방법은 카프카 포트번호(default 9092)를 사용중인 카프카를 종료시키고 재실행하는 것이다.즉, 9092 포트를 사용중인 프로세스를 종료시키면된다.sudo lsof -t -i tcp:9092 | xargs kill -9mac 기준이라 다른환경에서는 잘모르겠다." }, { "title": "[Trouble Shooting] Could not find gem &#39;nokogumbo(~&gt; 2.0)&#39; 해결하기", "url": "/posts/trouble-shooting-could-not-find-gem-'nokogumbo~-2.0'-%ED%95%B4%EA%B2%B0%ED%95%98%EA%B8%B0/", "categories": "etc", "tags": "", "date": "2020-12-03 21:13:00 +0800", "snippet": "Jekyll 엔진 기반의 블로그에 글을 작성하고 커밋을 했더니,github Actions에서 다음과 같은 에러가 발생하였다.Run bundle install --localResolving dependencies...Bundler could not find compatible versions for gem &quot;nokogumbo&quot;: In Gemfile: html-proofer was resolved to 3.16.0, which depends on nokogumbo (~&amp;gt; 2.0)Cou..." }, { "title": "Topic Configurations", "url": "/posts/partitions-and-segments/", "categories": "DataEngineering, Kafka", "tags": "", "date": "2020-12-03 18:01:00 +0800", "snippet": "Segment 토픽들은 파티션으로 구성되 있음 파티션들은 segment로 이루어져 있음 오직 기록되고 있는 segment만 활성화 되어있음 세그먼트는 두개의 index(파일)로 구성됨 offset : kafka가 읽어야하는 위치를 찾기위한 인덱스 timestamp : timestamp를 가진 메시지들을 찾기 위한 인덱스 카프카는 constant time에 데이터를 찾음. ..." }, { "title": "Travis CI에서 Spring boot app 테스트하기", "url": "/posts/travis-ci%EC%97%90%EC%84%9C-spring-boot-app-%ED%85%8C%EC%8A%A4%ED%8A%B8%ED%95%98%EA%B8%B0/", "categories": "CI", "tags": "", "date": "2020-12-03 13:03:00 +0800", "snippet": "Spring Boot 앱을 CI를 통해서 테스트를 하고 도커로 배포하기 하려는 과정중에 테스트가 실패하는 현상이 발생했다.이유는 Spring Boot 앱의 테스트 코드가 배포환경의 Database에 의존했기 때문이었다.이 문제들 다음과 같이 해결하였다.1. Mockito를 이용해서 각각의 layer들을 독립적으로 테스트하도록 리펙토링처음 시도한 방법은 service 와 rest controller에서 의존하고있는 객체들을 Mockito를 이용해서 mocking하는 방법으로 변경하였다.다음은 UserService를 Mockito..." }, { "title": "ETL Pipeline", "url": "/posts/etl-pipeline/", "categories": "DataEngineering, Concept", "tags": "", "date": "2020-12-01 16:22:00 +0800", "snippet": "ETL PipelineETL Pipeline이란 input source로 부터 데이터를 추출하고(extracting), 데이터를 변환하고, database, data mark, data warehouse에 저장하는 과정들을 말한다.출처Extract, Transform, Load 의 약자이다.Extract데이터는 다양한 source로 부터 추출될수 있다. 데이터는 구조화되어있을 수도 있지만 그렇지 않을수도 있다.Transform데이터를 다양한 application에서 사용될수 있도록 포맷을 변환하는 과정을 말한다.Load일정한 ..." }, { "title": "Java에서 array의 타입", "url": "/posts/java%EC%97%90%EC%84%9Carray%EC%9D%98-%ED%83%80%EC%9E%85/", "categories": "Java", "tags": "", "date": "2020-12-01 12:37:00 +0800", "snippet": "자바에서 배열은 primitive type인가 아니면 object인가?위와 관련해서 다음 글을 찾아보았고 번역해보았다.Java에서 Array는 object로 간주된다. 이유는 array가 new 키워드로 생성될수 있기 때문이다. new 키워드는 항상 object를 생성하기 위해서 사용된다.array의 direct parent class or super class는 ‘Object’ class이고 Java에서 모든 array type은 특정 클래스에 속한다. 이점은 integer array type에, double array ty..." }, { "title": "Apache Kafka 장단점", "url": "/posts/kafka-%EC%9E%A5%EB%8B%A8%EC%A0%90/", "categories": "DataEngineering, Kafka", "tags": "", "date": "2020-11-30 21:38:00 +0800", "snippet": "Apache Kafka의 장점 Low Latency : 10 millisecond까지 low latency value를 제공한다. High Throughput : low latency 덕분에, Kafka는 메시지들을 더 많이, 빠르게 전달할수 있다. Fault Tolerance : Kafka는 cluster 내에있는 node나 machine의 실패에 대처하는 방법을 갖고 있음. Durability : Kafka는 replication 기능을 제공하는데, cluster내에 다른 노드..." }, { "title": "[Leetcode] Partition Equal Subset Sum - memoization 적용", "url": "/posts/leetcode-partition-equal-subset-sum-memoization-%EC%A0%81%EC%9A%A9/", "categories": "Algorithm", "tags": "", "date": "2020-11-28 10:29:00 +0800", "snippet": "FANG에서 출제된 문제는 보기보다 간단한 경우가 많은것 같다. 처음에는 backtracking으로 접근을 하긴 했지만 시간복잡도가 O($2^N$)이기 때문에 접근을 포기했다. DP로 풀자니 어떤 부분을 subproblem으로 나눠야 하는지 잘 보이지 않았고, 더 오래 고민했으면 풀수도 있었을것 같다.다음은 Top down DP로 풀이한 코드이다.import java.util.HashMap;import java.util.Map;class Solution { public boolean canPartition(int[] nu..." }, { "title": "[BOJ 1038-감소하는수] 집합이론을 이용한 추론", "url": "/posts/boj-1038-%EA%B0%90%EC%86%8C%ED%95%98%EB%8A%94%EC%88%98-%EC%A7%91%ED%95%A9%EC%9D%B4%EB%A1%A0%EC%9D%84-%EC%9D%B4%EC%9A%A9%ED%95%9C-%EC%B6%94%EB%A1%A0/", "categories": "Algorithm", "tags": "", "date": "2020-11-26 13:09:00 +0800", "snippet": "문제에서 과연 몇번째 감소하는 수까지 존재하는 것일까? 잠깐 생각했을때는 감소하는 수는 무한히 존재할것 그렇지 않다.결론적으로는 1023개, 1022번째 까지 가능하다.{0,1,2,3,4,5,6,7,8,9}와 같은 집합이 있을때 이를 가지고 감소하는 수를 만들수 있는 경우는 몇가지 일까?여기서 우리는 strictly decresing 한 경우만을 따지는 것이므로 위의 모든 부분집합은 감소하는 수를 오직 하나로 결정할수 있다. 단, 여기서 공집합은 제외를 하여야한다.결과적으로 감소하는 수의 최대개수는 $2^{10}-1 = 102..." }, { "title": "[Leetcode] Smallest Integer Divisible by K", "url": "/posts/leetcode-smallest-integer-divisible-by-k/", "categories": "Algorithm", "tags": "", "date": "2020-11-26 11:03:00 +0800", "snippet": "위 문제에 수열이 1,11,111,1111,… 이므로 다음 식이 성립한다.next = prev * 10 + 1이 문제의 핵심은 다음수와 현재수 사이에 모듈러 관계를 파악하는 것이다.결론적으로 말하면 모듈러 관계는 다음과 같다.A = prev % KB = next % K = (A*10 + 1) % K 이제 위식을 좀더 풀어 쓰면 다음과 같다.B = next % K= (prev * 10 + 1) % K= ((prev * 10) % K + 1 % K) % K= ((prev % K) * (10 % K) + 1 % K) % K= (A ..." }, { "title": "[Inversion of Control 이해하기] Chapter 4 - IoC Container", "url": "/posts/ioc-container/", "categories": "SoftwareEngineering", "tags": "", "date": "2020-11-25 21:11:00 +0800", "snippet": "IoC ContainerIoC Container(DI Container)는 automatic dependency injection을 구현하기 위한 프레임워크이다. IoC는 객체생성과 life-time을 관리하고 클래스에 대한 의존성을 주입한다.IoC 컨테이너는 run time에 특정 class 객체를 생성하고 모든 dependency 객체들을 constructor, property 또는 method를 통해서 주입하며, 적절한 시기에 이들을 소멸시킨다. 이 모든과정이 우리가 신경쓸 필요없이 자동으로 일어난다. 따라서 수동으로 객..." }, { "title": "[Inversion of Control 이해하기] Chapter 3 - Dependency Injection", "url": "/posts/dependency-injection/", "categories": "SoftwareEngineering", "tags": "", "date": "2020-11-25 20:00:00 +0800", "snippet": "Dependency Injection(DI)는 IoC를 구현하기위해 사용되는 디자인 패턴이다. DI는 의존하는 객체들을 class 밖에서 생성하도록 허락하며, 그러한 객체들을 여러가지 방법을 통해서 class에 제공해준다.Dependency Injection pattern은 3가지 유형의 클래스를 포함한다. Client Class: The client class (dependent class)는 service class에 의존하는 클래스를 뜻한다. Service Class: The service class..." }, { "title": "[Inversion of Control 이해하기] Chapter 2 - DIP(Dependency Inversion Principle)", "url": "/posts/dipdependency-inversion-principle/", "categories": "SoftwareEngineering", "tags": "", "date": "2020-11-25 19:58:00 +0800", "snippet": "Dependency Inversion PrincipleDIP의 정의 High-level 모듈들은 low-level 모듈들을 의존해서는 안된다. 둘다 Abstraction에 의존해야한다. Abstraction들은 detail들에 의존해서는 안된다. Detail들은 abstraction들에 의존해야한다. DIP를 이해하기 위해서 아래의 코드를 보자.public class CustomerBusinessLogic{ public CustomerBusinessLogic() { } public ..." }, { "title": "[Inversion of Control 이해하기] Chapter 1 - Inversion of Control의 정의와 예시", "url": "/posts/inversion-of-control/", "categories": "SoftwareEngineering", "tags": "", "date": "2020-11-25 19:54:00 +0800", "snippet": "Overview출처위 그림에서 보듯이 IoC와 DIP는 class들을 디자인할때 사용되어야 하는 high level design principle들이다. principle이기 때문에 best practice를 추천해주긴 하지만 구체적인 구현사항을 제공하지는 않는다. DI는 pattern이고 IoC container는 framework이다.Inversion of ControlIoC는 클래스들 사이에 느슨한 커플링(loose coupling)을 달성하기 위해서 여러종류의 control을 뒤집는 것을 추천하는 principle이다...." }, { "title": "Design Principle vs Design Pattern", "url": "/posts/design-principle-vs-design-pattern/", "categories": "SoftwareEngineering", "tags": "", "date": "2020-11-25 17:40:00 +0800", "snippet": "Software engineering에서 design principle과 design pattern은 같지 않다.Design Principle Design Principle은 소프트웨어를 잘 디자인하기 위한 high level 가이드라인을 제공한다. 구현에 대한 가이드라인은 제공하지 않는다. 대표적으로는 SOLID(SRP, OCP, LSP, ISP, DIP)가 있다. 예를들어, Single Responsibility Principle (SRP)는 모든 클래스는 하나의 책임만 가지며..." }, { "title": "iTerm2 setting", "url": "/posts/iterm2-setting/", "categories": "Settings", "tags": "", "date": "2020-11-23 20:51:00 +0800", "snippet": "mac에서 아름다운 터미널을 설정하기 위한 링크를 소개한다.link" }, { "title": "Binary Numeric Promotion", "url": "/posts/binary-numeric-promotion/", "categories": "Java", "tags": "", "date": "2020-11-22 09:56:00 +0800", "snippet": "Binary Numeric Promotionoperator가 binary numeric promotion을 operand들에게 적용할때, numeric type으로 변환되는 값을 명시해줘야 하며, 다음과 같은 규칙을 따른다.순서대로 살펴보면 다음과 같다.1. 만약 reference type이라면, unboxing conversion을 수행한다.Unboxing Conversion이란 아래와 같은 변환을 말한다.From type Boolean to type booleanFrom type Byte to type byteFrom ty..." }, { "title": "SQL Statements", "url": "/posts/sql-statements/", "categories": "Database, Theory", "tags": "", "date": "2020-11-18 10:47:00 +0800", "snippet": "SQL Statements     Session Management CONNECT, DISCONNECT Data Retrieval SELECT Data Manipulation Language(DML) INSERT, UPDATE, DELETE, TRUNCATE, MERGE Data Definition Language(DDL) CREATE, DROP, ALTER, RE..." }, { "title": "Sequence", "url": "/posts/sequence/", "categories": "Database, Theory", "tags": "", "date": "2020-11-18 10:36:00 +0800", "snippet": "Sequence 자동적으로 유일한(unique) 순차 값을 생성하는 Database Object. 기본키(primary key)의 값을 생성하는데 주로 사용됨. 메모리에 cache되었을때 시퀀스 값에 대한 접근의 효율성이 증가함. 다른 사용자들에 의해 공유가능 시퀀스는 테이블과는 독립적으로 저장되고 생성된다. " }, { "title": "Read Consistency", "url": "/posts/read-consistency/", "categories": "Database, Theory", "tags": "", "date": "2020-11-17 21:39:00 +0800", "snippet": "Read ConsistencyTransaction-level read consistency (트랜젝션 수준 읽기 일관성) 트랜젝션의 각 SQL문의 질의는 그 트랜젝션 시작전에 커밋한 데이터만을 본다. 물론 해당 트랜젝션이 변경한 데이터는 볼수있다. Statement-level read consistency(statement 수준 읽기 일관성) 트랜젝션의 각 SQL문의 질의는 그 statement 시작전에 commit한 data만을 본다. 물론 해당 트랜젝션이 변경한 데이터는 볼수있다. " }, { "title": "B-Tree Indexing", "url": "/posts/b-tree-indexing/", "categories": "Database, Theory", "tags": "", "date": "2020-11-16 18:55:00 +0800", "snippet": "B-Tree란 무엇인가?B-tree는 정열된 순서로 데이터를 저장할때 사용하는 자료구조이다. 샘플 B-tree는 다음과 같다.출처각각의 노드에 키값들은 두개의 reference를 가지고 있으며, 각각의 reference는 다른 자식노드를 가리킨다. 왼쪽에 위치한 자식노드는 현재 키 값보다 작으며, 오른쪽에 위치한 자식노드는 현재 키 값보다 크거나 같다.DB에서 인덱싱을 사용하는 이유 Type Insertion Deletion Lookup Unsorte..." }, { "title": "HTTPS Handshake with TLS", "url": "/posts/https-handshake-with-tls/", "categories": "Network", "tags": "", "date": "2020-11-16 16:55:00 +0800", "snippet": "HTTPS Handshake with TLS 1.2https:// 프로토콜 prefix로 HTTP 리퀘스트를 보내면, 먼저 TCP connection이 3-way handshake를 사용해서 설정된다. 아래의 파란선이 연결수립과정이다. HTTPS 프로토콜의 기본 포트번호는 443이다.출처TCP 커넥션이 일어나고, TLS handshake이 일어난다.1. client가 TLS 1.2 protocol layer로 감싼뒤에 빈 패킷을 보낸다. 이 layer는 metadata와 Client Hello 메세지를 포함한다. 보낼때 ..." }, { "title": "Method Signature", "url": "/posts/method-signature/", "categories": "Java", "tags": "", "date": "2020-11-16 13:32:00 +0800", "snippet": "Method Signature란?Java에서 method signature란 함수명,파라미터의 타입,갯수,순서를 말한다. 리턴타입과 thrown exception들은 method signature의 일부로 간주되지 않는다.예를 들면, 다음 두 메소드는 다른 signature를 가진다.doSomething(String[] y);doSomething(String y);다음의 세 메소드들은 같은 signature를 가진다.int doSomething(int y) String doSomething(int x)int doSomethin..." }, { "title": "Trigger", "url": "/posts/trigger%EC%9D%98-%EC%9E%A5%EB%8B%A8%EC%A0%90/", "categories": "Database, Theory", "tags": "", "date": "2020-11-16 10:15:00 +0800", "snippet": "트리거란? INSERT, UPDATE 또는 DELETE문이 TABLE에 대해 행해질때 implicitly 수행되는 프로시저이다. Data Integrity 유지와 table이 변경될때 필요한 동작을 명시하기 위해 사용된다. 트리거의 장점 복잡한 data integrity를 구현가능. rule이나 check constraint로서 구현하기 힘든 복잡한 처리도 트리거로 구현 가능data integrity란 ‘DB에 잘못된 데이터가 들어오는 것을 막는방법’ 역정규화된 데이터 관리가능때로는 Join을 줄이기..." }, { "title": "VS Code에서 java 버전 수동으로 세팅하기", "url": "/posts/vs-code-java-%EB%B2%84%EC%A0%84%EC%84%B8%ED%8C%85/", "categories": "Settings", "tags": "", "date": "2020-11-14 08:12:00 +0800", "snippet": "Java Intellisense를 VS code에서 사용하려면 Java11 이상 버전이 필요하다고 한다. 하지만 외부 터미널에서는 계속 Java8을 사용하고 싶다면, 다음과 같이 하면된다. Preferences -&amp;gt; Settings 검색창에 Java라고 검색 Java:Home 섹션 밑에 Edit in settings.json 선택 다음 라인추가 &quot;java.home&quot;: &quot;/Library/Java/JavaVirtualMachines/jdk-14.0.2.jdk/Contents/H..." }, { "title": "webpack", "url": "/posts/webpack/", "categories": "Web", "tags": "", "date": "2020-11-13 19:20:00 +0800", "snippet": "Webpack이란?간단히 정의하면 module bundler이다.각각의 파일들에 의존관계를 명시함으로서 의존관계를 참고하여 파일들을 묶을수 있게 한다.Webpack은 왜쓰는가? module들을 하나의 파일에 정의하도록 하면 안되는가?웹 리소스들(js,css,assets)들은 서로간의 의존성때문에 특정한 순서대로 정의되어야한다.수동으로 이러한 리소스들의 정의순서를 세팅해주기는 힘들기때문에 사용한다." }, { "title": "command-line 명령어", "url": "/posts/command-line-%EB%AA%85%EB%A0%B9%EC%96%B4/", "categories": "Linux", "tags": "", "date": "2020-11-13 12:29:00 +0800", "snippet": "~/ 란 무엇인가?~/란 /home/user_name을 의미한다.iTerm2에서 source ~/.bash_profile 자동으로 실행되게 하기 Settings 열기(Cmd + ‘,’ 단축키로도 가능)) General Tab에 Command 속성에 Send text at start 부분에 source ~/.bash_profile 입력export의 의미예시 1export CONFLUENT_HOME=&quot;/Users/jaegu/confluent-6.0.0&quot;CONFLUENT_HOME 변수에 “/Users/jaegu..." }, { "title": "[Leetcode] Permutations II", "url": "/posts/leetcode-permutations-ii/", "categories": "Algorithm", "tags": "", "date": "2020-11-13 10:33:00 +0800", "snippet": "처음 내가 푼 방식은 다음과 같다. hashMap에 0~n-1(n은 인풋갯수)범위 숫자를 저장 deque에 숫자의 인덱스값을 추가, 그리고 해당 idx가 추가되었으므로 hashMap에 해당 인덱스를 삭제한다. deque가 인풋으로 들어온 숫자의 갯수와 일치하면 순열을 표현하는 문자열을 만들고 그것과 기존에 추가했던 순열정보와 중복되었는지 비교한다. 중복이 되지않았으면 deque에 있는 idx순서대로 인풋값을 새로운 list에 푸시한다.최종적으로 새로운 list를 결과 배열에 푸시한다.class Solution { S..." }, { "title": "REST의 정의와 6가지 원칙", "url": "/posts/rest/", "categories": "Network", "tags": "", "date": "2020-11-12 19:57:00 +0800", "snippet": "RESTful APIRepresentational State Transfer의 약자이다. 인터넷상의 자원을 정의하고 자원에 대한 주소를 지정하는 방법 전반에 대한 패턴6가지 원칙1. Client-Server client application과 server application은 반드시 서로간의 의존성 없이 개발되어야한다. client는 오직 URI만을 알고있어야한다.2. Stateless 서버는 클라이언트가 요청한 HTTP request에 대해서 아무것도 저장해서는 않는다. 만약 클라이언트 앱이 stateful appli..." }, { "title": "Transaction Isolation Level", "url": "/posts/transaction-isolation-level/", "categories": "Database, Theory", "tags": "", "date": "2020-11-12 19:05:00 +0800", "snippet": "트랜잭션 고립 수준 (Transaction Isolation Level) 트랜잭션들끼리 일관성있는 데이터를 얼마나 허용할 것인지 정해놓은 수준 즉, 트랜잭션 수행 중 다른 트랜잭션이 해당 데이터를 조회하는 것이 가능한지의 정도를 결정해 놓은 것 고립 수준이 높을 수록 일관성은 보장되지만 그만큼 동시성이 떨어진다. (성능 하락) 고립 수준 설명 Read Uncommited (Level 0) - 트랜잭션 수행 중이거나 아직 commit 되지 않은 데이터를 다..." }, { "title": "Cloud 환경 Architecture", "url": "/posts/cloud%ED%99%98%EA%B2%BDarchitecture/", "categories": "Cloud", "tags": "", "date": "2020-11-12 18:44:00 +0800", "snippet": "호스트형 가상화 방식하드웨어 위에 Hypervisor OS를 설치하고 그 위에 가상 서버를 구현하는 방식입니다.장점한대의 물리서버에 여러 환경에서 동작하는 서버들을 실행할수 있기때문에 자원활용도가 증가단점여러 서버가 한대의 하드웨어를 공유하므로 서버한대당 사용가능한 자원이 줄어든다. 즉, 성능이 떨어진다.Bare Metal 방식하드웨어 위에 Hypervisor OS설치없이 설치하고 싶은 OS를 직접 하드웨어 위에 설치하는 방식장점하나의 서버가 하드웨어의 모든 성능을 사용할 수 있음.단점여러 서버를 가상화방식으로 실행할때보다 하..." }, { "title": "Docker의 장점과 단점", "url": "/posts/docker%EC%9D%98-%EC%9E%A5%EC%A0%90%EA%B3%BC-%EB%8B%A8%EC%A0%90/", "categories": "Docker", "tags": "", "date": "2020-11-12 13:51:00 +0800", "snippet": "장점 실행속도가 빠르다.OS를 실행하지 않고도 모든 프로세스에 대한 컨테이너를 실행할수있기 때문에 실행속도가 빠르다. 안전하다.container들끼리는 분리되어있기때문에 보안상 이점이있다. 실행환경 구성이 빠르고 간단하다.프로젝트 개발 및 실행환경을 강제화 가능 비용절감 효과컨테이너의 크기가 매우 작고, 하나의 물리적 서버에 다수의 컨테이너를 가동시킬 수 있음. 단점 Docker는 플랫폼 의존적이다.Docker는 실제로 Windows와 Mac에서는 linux 가상머신위에..." }, { "title": "Multilevel Feedback Queue Scheduling(MLFQ)", "url": "/posts/multilevel-feedback-queue-schedulingmlfq/", "categories": "OS", "tags": "", "date": "2020-11-10 16:53:00 +0800", "snippet": "이번글은 링크에 있는 글을 번역한 글입니다.이 스케줄링은 Multilevel Queue(MLQ)와 흡사하지만 프로세스가 큐들사이를 이동할수 있습니다. MLFQ는 프로세스들의 행동(실행시간)을 분석하여 우선순위를 바꿉니다.위그림에서 queue1과 queue2가 round robin (각각 time quantum 4,8) 으로 스케줄링 되고 queue3는 FCFS로 스케줄링 된다고 가정합니다.MFQS의 한가지 구현방법은 아래와 같습니다. 처음 들어오는 프로세스들은 queue1으로 들어갑니다. queue1에서 ..." }, { "title": "five classes of IPv4", "url": "/posts/five-classes-of-ipv4/", "categories": "Network", "tags": "", "date": "2020-11-09 20:23:00 +0800", "snippet": "ipv4의 first octet부분을 빨리 알고싶으면 아래그림을 참고하면된다.classA의 시작값은 0classB의 시작값은 128classC의 시작값은 128+64=192classD의 시작값은 128+64+32=224classE의 시작값은 128+64+32+16=240h = $2^{x}-2$, x : no of zerosn = $2^{y}$, y : no of ones출처 : Sunny Class" }, { "title": "Web Dev Commands", "url": "/posts/web-dev-commands/", "categories": "Shortcut", "tags": "", "date": "2020-11-01 17:59:00 +0800", "snippet": " Show console/Close inspect windowCmd + Option + J Show elementCmd + Option + C Kill process concerned with port 8000sudo lsof -t -i tcp:8000 | xargs kill -9 Exporting Spring Boot application to jar file with maven` ./mvnw clean package` Exporting Spring Boot appl..." }, { "title": "[LeetCode] Recover Binary Search Tree", "url": "/posts/RecoverBinarySearchTree/", "categories": "Algorithm", "tags": "", "date": "2020-11-01 00:00:00 +0800", "snippet": "먼저 이문제를 풀때 comparator함수를 작성할때 주의할점이 있다. sortedList.sort(new Comparator&amp;lt;TreeNode&amp;gt;() { @Override public int compare(TreeNode n1, TreeNode n2) { return n1.val - n2.val; } });위와같이 작성했을때 $-2^{31}$ 에서 $2^{31}-1$ 이기 때문에 두수를 빼면 int 범위를 ..." }, { "title": "OAuth2 정리하기", "url": "/posts/OAuth2/", "categories": "Security", "tags": "", "date": "2020-10-29 19:17:00 +0800", "snippet": "OAuth2란? application이 Facebook, Github 같은 HTTP 서비스에 대한 사용자 계정에 접근을 할수 있도록하는 인증 framework. 사용자 인증을 사용자 계정을 호스팅하고 있는 서비스에 맡기고 third-party application에게 사용자 계정에 대한 정보에 접근 할수 있도록 권한을 부여 web app, desktop app, mobile app에게 authorization flow를 제공해줌 참고링크Grant Type : Authorization Code 유저에게 인가요청 유저가..." }, { "title": "[Travis CI] docker image 빌드하여 dockerhub에 푸시작업 자동화하기", "url": "/posts/dockerhub/", "categories": "CI", "tags": "", "date": "2020-10-28 00:00:00 +0800", "snippet": "1) 프로젝트 루트폴더에 .travis.yml 파일을 생성한다.2) .travis.yml 파일을 다음과 같이 작성한다.dist: trustyenv: global: - DOCKER_USER=&quot;USERNAME&quot; - DOCKER_PASS=&quot;PASSWORD&quot;jobs: include: - stage: build safe-place images and push to dockerhub repository script: - echo &quot;$DOCKER_PASS&quot; | doc..." }, { "title": "[Docker] docker--compose.yml을 정의하여 Spring boot app 과 MySQL 앱 동시에 실행할때 Connection Link Failure 에러 해결하기", "url": "/posts/dockerCompose/", "categories": "Docker", "tags": "", "date": "2020-10-27 00:00:00 +0800", "snippet": "내가 정의한 커스텀 MySql 이미지와 Spring Boot 서버를 docker-compose를 실행하는데 Connection Link Failure에러가 자꾸 났다.원인은 의외의 곳에 있었다.커스텀 MySql 이미지가 다 실행되기도 전에 Spring Boot 서버가 실행되었기 때문이다.사실 depends_on: - safe-place-db구문이 실행되면 실행의 순서가 보장되리라고 생각했는데, 실제로는 safe-place-db가 up 될때까지 보장해주는 것이었다. up이 된 순간 부터는 두가지 컨테이너가 동시에 실행되는 것이..." }, { "title": "[Spring Boot] Spring 2.x 버전에서 JAR로 Packaging 하는 것에 대하여", "url": "/posts/jarPackaging/", "categories": "Spring", "tags": "", "date": "2020-10-26 00:00:00 +0800", "snippet": "Spring Boot 2.x 버전의 앱을 JAR로 패키징하는데 꽤나 많은 시간을 소비하였는데, 2.x 이전버전의 경우를 시도하다 보니 시행착오를 많이했다. 스택오버플로우 에서 찾아보면서 꼼꼼히 읽는 훈련을 계속 해야겠다.해답은 간단했다.Spring Boot 2.x 버전에서 bootJar과 bootWar 이라는 gradle task가 app을 패키징하는 역할을 한다.bootJar task는 실행가능한 jar file을 만드는데 책임을 지고 이는 java plugin이 적용이 될때 자동으로 생성된다고 한다.따라서 build.gra..." }, { "title": "[Docker] 자주 사용하는 커멘드", "url": "/posts/dockerCommands/", "categories": "Docker", "tags": "", "date": "2020-10-26 00:00:00 +0800", "snippet": "docker-compose up-Builds, (re)creates, starts, and attaches to containers for a service(-d, --detach : Detached Mode, Run container in background.)docker rmi &amp;lt;your-image-id&amp;gt; : delete image with iddocker images : list docker imagesdocker build --tag &amp;lt;tag-name&amp;gt; . : build..." }, { "title": "[Trouble Shooting] Spring Maven Project에서 갑자기 api endpoint에 404 error가 뜰때 + Dynamic Web Module to x.x Error in Eclipse", "url": "/posts/DynamicWebModuleError/", "categories": "Spring", "tags": "", "date": "2020-10-24 00:00:00 +0800", "snippet": "Spring Maven Project에서 갑자기 api endpoint에 404 error가 뜰때Git의 커밋로그를 분석하여 차이가 발생한 부분을 찾아보았다. 프로젝트의 .classfile에 다음 라인이 누락삭제되어서 발생하였다.&amp;lt;attribute name=&quot;org.eclipse.jst.component.dependency&quot; value=&quot;/WEB-INF/lib&quot;/&amp;gt;이 라인이 어쩌다가 누락이 된것인지는 확실치 않지만 잘되던 프로젝트가 갑자기 안될때는 커밋로그를 분석하..." }, { "title": "주니어 개발자 또는 인턴으로 살아남기 위한 팁 요약", "url": "/posts/%EC%A3%BC%EB%8B%88%EC%96%B4-%EA%B0%9C%EB%B0%9C%EC%9E%90-%EB%98%90%EB%8A%94-%EC%9D%B8%ED%84%B4%EC%9C%BC%EB%A1%9C-%EC%82%B4%EC%95%84%EB%82%A8%EA%B8%B0-%EC%9C%84%ED%95%9C-%ED%8C%81-%EC%9A%94%EC%95%BD/", "categories": "CareerTip", "tags": "", "date": "2020-10-23 00:00:00 +0800", "snippet": " 인턴십(또는 신입으로서 일)을 시작하기 전에 팀멤버들을 만나서 소통하라. 자신을 소개하라. 멍청한 질문이라는건 존재하지 않는다, 주저하지 말고 질문하되 그 질문에 답을 해줄수 있는 적절한 사람에게 하라. 질문하기전에 문제에대해서 충분히 고민해보고 해결하려고 노력하라. 스스로 모든 문제를 해결하려고 하지마라. 반드시 코드를 제출하기전에 테스트를 충분히 작성하라. (테스트를 작성하지 않은 코드는 쓸모없다.) 데드라인을 넘겼다고 해서 세상종말인 것은 아니다. ..." }, { "title": "[BOJ 1339-단어수학] 시간초과 원인(Math.pow가 병목의 원인)", "url": "/posts/boj1339/", "categories": "Algorithm", "tags": "", "date": "2020-10-22 03:05:00 +0800", "snippet": "먼저 accept된 코드를 보자.public static int getSum(Deque&amp;lt;Character&amp;gt; perm){ HashMap&amp;lt;Character,Integer&amp;gt; valueMap = new HashMap&amp;lt;&amp;gt;(); int cur = 9; Iterator&amp;lt;Character&amp;gt; iter = perm.iterator(); while (iter.hasNext()){ ..." }, { "title": "10.22 학습한 sql 구문", "url": "/posts/sql/", "categories": "Database, SQL", "tags": "", "date": "2020-10-22 00:00:00 +0800", "snippet": "user 조회select host, user, authentication_string from user;유저 삭제drop user springstudent@&#39;%&#39;외부에서 접근 가능하도록 유저 생성create user springstudent@&#39;%&#39; identified by &#39;springstudent&#39;;local에서만 접근 가능하도록 유저 생성:create user springstudent@localhost identified by &#39;springstudent&#39;;spring..." }, { "title": "[DB Trouble Shooting]public key retrieval is not allowed", "url": "/posts/public-key-retrieval-is-not-allowed/", "categories": "Database, MySQL", "tags": "", "date": "2020-10-22 00:00:00 +0800", "snippet": " mysql 8.x 버전 이후로 발생 jdbc url에 allowPublicKeyRetrieval=true&amp;amp;useSSL=false 필요 예시: jdbc:mysql://localhost:3306/dev-product?useUnicode=true&amp;amp;characterEncoding=utf8&amp;amp;allowPublicKeyRetrieval=true&amp;amp;useSSL=false 출처 " }, { "title": "[DB 상식] Migration이란?", "url": "/posts/migration/", "categories": "Database, MySQL", "tags": "", "date": "2020-10-22 00:00:00 +0800", "snippet": "마이그레이션(migration)이란 한 종류의 데이터베이스에서 다른 종류의 데이터베이스로 데이터를 옮기는 것을 의미한다" }, { "title": "[DB Trouble Shooting] java.sql.SQLException - Access denied for user 예외", "url": "/posts/accessdeniedforuser/", "categories": "Database, MySQL", "tags": "", "date": "2020-10-22 00:00:00 +0800", "snippet": "아래와 같이 선언해서는 위의 에러가 계속 발생한다.grant all privileges on moBack to &#39;springstudent&#39;;다음과 같이 선언하면 에러가 해결된다.grant all privileges on moBack.* to &#39;springstudent&#39;@&#39;%&#39;;" }, { "title": "[Master The Graph Theory] [BOJ 1261] 알고스팟", "url": "/posts/%EC%95%8C%EA%B3%A0%EC%8A%A4%ED%8C%9F/", "categories": "Algorithm", "tags": "", "date": "2020-10-07 00:00:00 +0800", "snippet": "위 문제를 풀때, visited에 해쉬값을 다음과 같이 적용하여 계속 오답이 났다.String key = String.format(&quot;%s%s&quot;, front.row, front.col); 위와 같이 visited를 갱신하면 셀을 유일하게 구분할수 없는 경우가 생긴다.예를들면, (1,11) 과 (11,1)의 경우에 둘다 key값이 “111” 이 되기 때문이다.따라서 둘사이에 구분자를 추가하여 1 | 11 , 11 | 1이 서로 다른 key를 갖도록 수정하여야한다.그리고 2차원 배열을 선언하는것이 괜찮다면 이차원 ..." }, { "title": "[ROAD TO DATA ENGINEER] Kafka Basic Concepts", "url": "/posts/kafka-basic-concepts/", "categories": "DataEngineering, Kafka", "tags": "", "date": "2020-10-06 00:00:00 +0800", "snippet": "Why do we use Kafka?Without KafkaWith KafkaTopic 특정한 data stream database의 테이블과 비슷한 개념 원하는 만큼 생성가능 이름으로 구분됨(identified by name) Topic들은 partition으로 나누어짐 각각의 파티션은 정렬되어있음 partition 내에 있는 메시지들은 offset이라 불리는 incremental한 아이디를 가진다. ( partition 0, partition 1, ..." }, { "title": "[Spring] [Trouble Shooting] java.lang.IllegalStateException: No WebApplicationContext found: no ContextLoaderListener registered?", "url": "/posts/java.lang.illegalstateexception-no-webapplicationcontext-found-no-contextloaderlistener-registered/", "categories": "Spring", "tags": "", "date": "2020-10-05 00:00:00 +0800", "snippet": "Spring에서 default로 주어져있는 index.jsp를 사용할때 `java.lang.IllegalStateException: No WebApplicationContext found: no ContextLoaderListener registered? `에러를 만날 수 있다.이때는 index.jsp 파일을 view폴더에 넣고 다음과 같이 컨트롤러를 정의하여 해결할수 있다.package com.gameTodoeyBackendClient.controller;import org.springframework.stereotype.C..." }, { "title": "[Hackerrank] Top Competitors", "url": "/posts/master-the-sql-hackerrank-top-competitors/", "categories": "Database, SQL", "tags": "", "date": "2020-10-01 00:00:00 +0800", "snippet": "SELECT H.HACKER_ID, H.NAMEFROM HACKERS H, DIFFICULTY D, CHALLENGES C, SUBMISSIONS SWHERE H.HACKER_ID = S.HACKER_ID AND D.DIFFICULTY_LEVEL = C.DIFFICULTY_LEVEL AND C.CHALLENGE_ID = S.CHALLENGE_ID AND S.SCORE = D.SCOREGROUP BY H.HACKER_ID,H.NAMEHAVING COUNT(H.HACKER_ID) &amp;gt; 1ORDER BY COUNT(H.H..." }, { "title": "Hackerrank - Java Regex 2 - Duplicate Words Solution 해설", "url": "/posts/java-regex-2-duplicate-words-solution/", "categories": "regex", "tags": "", "date": "2020-09-26 00:00:00 +0800", "snippet": "import java.util.Scanner;import java.util.regex.Matcher;import java.util.regex.Pattern;public class JavaRegex2 { public static void main(String[] args) { String regex = &quot;\\\\b([a-z]|[A-Z]+)(\\\\s+\\\\1\\\\b)+&quot;; Pattern p = Pattern.compile(regex, Pattern.CASE_INSENSITIVE); ..." }, { "title": "[Master The Simulation 인구이동] Python 풀이시 시간초과 발생이유 및 해결책", "url": "/posts/%EC%9D%B8%EA%B5%AC%EC%9D%B4%EB%8F%99/", "categories": "Algorithm", "tags": "", "date": "2020-09-26 00:00:00 +0800", "snippet": "Python 풀이시 시간초과 발생이유 및 해결책from collections import defaultdict,dequefrom copy import deepcopyclass Solution: def checkBound(self,r,c): if r &amp;lt; 0 or r &amp;gt; self.n-1 or c &amp;lt; 0 or c &amp;gt; self.n-1: return False return True def checkMove(self,p..." }, { "title": "Order of execution of a Query (쿼리의 실행순서)", "url": "/posts/order-of-execution-of-a-query/", "categories": "Database, SQL", "tags": "", "date": "2020-09-24 00:00:00 +0800", "snippet": "Query order of execution (쿼리의 실행순서) FROM, JOIN subquery 포함가능, 임시 테이블들 생성가능 WHERE WHERE constraints에 적용되지 않는 rows 제거, FROM clause에 있는 칼럼들에 접근가능 SELECT에 있는 Aliases에는 접근 불가 (SELECT문은 아직 실행이 안된 상태이기 때문에) GROUP BY GROUP BY clause에 명시된 공통값들로 그룹화 됨 ..." }, { "title": "Spark와 Data Engineering 관련 프로젝트 시작하기", "url": "/posts/spark/", "categories": "DataEngineering, Spark", "tags": "", "date": "2020-09-24 00:00:00 +0800", "snippet": "What Is Spark?Open-source distributed general-purpose cluster-computing framework.How to start data engineering projects? Choose any framework, let’s say Kafka. Write some codes using that framework. Keep Expanding (try adding other technology)Project Idea : Creating Real Time REST API crawls..." }, { "title": "Apache Storm", "url": "/posts/apache-storm/", "categories": "DataEngineering, Storm", "tags": "", "date": "2020-09-22 00:00:00 +0800", "snippet": "Apache Storm 이란? 실시간 분산 컴퓨팅 시스템 무제한의 데이터 스트림을 쉽게 처리할수 있도록 해줌Storm vs Spark Streaming 진정으로 real time 처리를 원한다면, 사용하기 “sliding window” 뿐 아니라 “tumbling window”도 제공함. Kafka + Storm 으로 많이 사용" }, { "title": "[Master The Simulation] 어른 상어", "url": "/posts/%EC%96%B4%EB%A5%B8%EC%83%81%EC%96%B4/", "categories": "Algorithm", "tags": "", "date": "2020-09-21 00:00:00 +0800", "snippet": "from collections import defaultdict# 1: up, 2: down, 3: left, 4: rightclass Solution: def solve(self): n,m,k = [int(item) for item in input().split()] map = [] posDict = defaultdict(list) scentDict = defaultdict(list) offsetDict = {1:(-1,0),2:(1,0),3:(0,-..." }, { "title": "Synchronization", "url": "/posts/synchronization/", "categories": "OS", "tags": "", "date": "2020-09-15 00:00:00 +0800", "snippet": "Synchronization(동기화) 목적 : Race Condition방지, data corruption 방지 Race condition : 특정 접근 순서에 따라서 실행결과가 달라지는 경우 silient corruption : data corruption을 운이좋게 피해간 경우 Nonpreemptive kernel의 경우 race condition은 없지만 평균 대기시간 증가 Critical Section process들이 공유변수들을 수정할수 있는 코드의 영역Critica..." }, { "title": "Memory Management", "url": "/posts/memoryManagement/", "categories": "OS", "tags": "", "date": "2020-09-15 00:00:00 +0800", "snippet": "메모리관리의 목적다중 프로그래밍 실현을 위해 메모리에 많은 process들을 동시에 유지하기 위해서는 메모리 관리가 필요하다.Address Binding Timeprocess들의 메모리 주소를 결정하는 시점(Address Binding Time)은 크게 3가지가 있다. compile time binding : 만일 process가 memory내에 들어갈 위치를 컴파일 시간에 미리 알수있는 경우 load time binding : 이진코드를 재배치 가능 코드로 만들수 있는 경우 execution..." }, { "title": "Deadlock", "url": "/posts/deadlock/", "categories": "OS", "tags": "", "date": "2020-09-15 00:00:00 +0800", "snippet": "Deadlock모든 Proceess가 다른 process에 의해 야기될수 있는 event를 기다리고 있을때 발생발생조건 :1) Mutual Exclusion : 최소 하나의 자원이 비공유 모드로 지원되어야 함2) hold and wait : process는 최소하나의 자원을 점유한 상태로, 다른 process에 의해 점유된 자원을 얻기 위해 대기해야함3) No preemption : 자원들은 선점이 될 수 없고, 자발적으로만 방출될수 있다.4) circular wait : waiting process들이 순환적 대기를 해야한다..." }, { "title": "CPU Scheduling Algorithm", "url": "/posts/cpuScheduling/", "categories": "OS", "tags": "", "date": "2020-09-15 00:00:00 +0800", "snippet": "CPU Scheduling AlgorithmNon Preemptive SchedulingFCFS(First Come First Served) 도착한 순서에 따라 차례로 CPU를 할당하는 기법SJF(Shortest Job First) 실행 시간이 가장 짧은 프로세스에게 먼저 CPU를 할당하는 기법Preemptive SchedulingPriority Scheduling 가장 높은 우선순위를 가진 process를 schedule SJF는 Priority Scheduling의 special case ..." }, { "title": "Multilevel Queue (MLQ) Scheduling", "url": "/posts/MultilevelQueue/", "categories": "OS", "tags": "", "date": "2020-09-08 00:00:00 +0800", "snippet": "Multilevel Queue (MLQ) CPU Scheduling이란?ready queue에 있는 프로세스들을 스케줄링의 필요성에 따라 여러 종류로 나눠볼수 있다. 예를 들면, foreground(interactive) 프로세스들과 background(batch) 프로세스로 나눠 볼수 있다. 이 두 프로세스들은 다른 스케줄링 요구사항을 갖고있는데, 이것이 Multilevel Queue Scheduling이 사용되는 이유이다.작동방식Ready Queue를 여러 종류의 queue로 나눠보자. 예를들면, system process..." }, { "title": "TIME_WAIT이 필요한 이유", "url": "/posts/TIME_WAIT/", "categories": "Network", "tags": "", "date": "2020-09-07 00:00:00 +0800", "snippet": "TIME_WAIT 이 필요한 이유TIME_WAIT이 필요한 이유에 대해서 좋은 글을 발견했다. link이번 포스트에서는 TIME_WAIT 상태가 왜 필요하고, 왜 그렇게 길게 설정되어 있는지 이유를 살펴보자. 만일 TIME_WAIT이 짧다면 아래와 같은 두 가지 문제가 발생한다.첫 번째는 지연 패킷이 발생할 경우다.이미 다른 연결로 진행되었다면 지연 패킷이 뒤늦게 도달해 문제가 발생한다. 매우 드문 경우이긴 하나 때마침 SEQ까지 동일하다면 잘못된 데이타를 처리하게 되고 데이타 무결성 문제가 발생한다.두 번째는 원격 종단의 연..." }, { "title": "4-way handshake는 왜 4단계를 거쳐야하는가?", "url": "/posts/4wayHandshakeWhy4steps/", "categories": "Network", "tags": "", "date": "2020-09-07 00:00:00 +0800", "snippet": "다음은 stackoverflow에 올라온 질문에대한 번역글입니다.connection이 setup 되는 과정은 다음과 같다.(3-way-handshake)Client ——SYN—–&amp;gt; ServerClient &amp;lt;—ACK/SYN—- Server —-①Client ——ACK—–&amp;gt; Serverconnection이 terminate 되는 과정은 다음과 같다.(4-way-handshake)Client ——FIN—–&amp;gt; ServerClient &amp;lt;—–ACK—— Server —-②Cli..." }, { "title": "4-way-handshake에서 마지막 ACK 가 유실된다면?", "url": "/posts/4wayHandshakeLastAckLost/", "categories": "Network", "tags": "", "date": "2020-09-07 00:00:00 +0800", "snippet": "이글은 stack exchange에 올라온Why is the last ACK needed in TCP four way termination 질문에 대한 번역입니다. A —–FIN—–&amp;gt; BFIN_WAIT_1 CLOSE_WAITA &amp;lt;—-ACK—— BFIN_WAIT_2 (B can send more data here, this is &amp;gt;half-close state) A &amp;lt;—-FIN—— BTIME_WAIT LAST_ACKA —–ACK—–&amp;gt; B|..." }, { "title": "소프트웨어 개발분야정하기", "url": "/posts/log/", "categories": "Thoughts", "tags": "", "date": "2020-09-04 00:00:00 +0800", "snippet": "게임개발,ios앱개발,백엔드개발,웹프론트엔드 개발을 한번씩 맛보면서, 결국은 백엔드 개발로 진로를 정했다. 다른 개발분야에 대한 경험은 개발분야를 정하는데 있어서 모두 가치있는 경험들이었다.나는 개인적으로 UI의 로직처리를 내 업으로 하고싶지않았고, UI쪽 프로그래밍은 요구사항에 따라 빈번히 바뀌는 부분이라는 점도 나와는 별로 맞지 않았다.백엔드분야로 꼭 가야하는 이유는 분명하지 않지만, 코딩을 좋아하는 사람으로서 가장 끌리는 분야라고 밖에 현재는 말할수 없다. 그리고 추천알고리즘같은 대용량 데이터를 가지고 새로운 알고리즘을..." }, { "title": "Spring JPA 기본키 매핑하는 법", "url": "/posts/SpringJPAPrimaryKeyMapping/", "categories": "Spring", "tags": "", "date": "2020-09-04 00:00:00 +0800", "snippet": "오늘은 Spring JPA에서 기본키를 자동으로 생성하는 방법에 대해서 학습하였다.먼저 다음 내용은 내가 작성한것이 아님을 밝힌다. 출처IDENTITY 기본 키 생성을 데이터베이스에 위임하는 방법 (데이터베이스에 의존적) 주로 MySQL, PostgresSQL, SQL Server, DB2에서 사용합니다.SEQUENCE 데이터베이스 시퀀스를 사용해서 기본 키를 할당하는 방법 (데이터베이스에 의존적) 주로 시퀀스를 지원하는 Oracle, PostgresSQL, DB2, H2에서 사용합니다. @SequenceGenerat..." }, { "title": "Spring MVC 동작원리", "url": "/posts/HowSpringMVCWorks/", "categories": "Spring", "tags": "", "date": "2020-09-04 00:00:00 +0800", "snippet": "Spring 동작원리에 대해서 설명한 좋은 글을 발견했다. 이 글을 읽고 내 나름대로 요약해보았다.출처 link 사용자가 서버로 request Dispatcher-servlet은 Handler-Mapping에 request를 보내 해당하는 요청의 URL과 일치한 컨트롤러 정보를 요청, Handler-Mapping은 요청에 부합하는 컨트롤러를 탐색하고 리턴 Dispatcher-servlet은 그 정보를 통해 컨트롤러와 연결 해당 컨트롤러는 흐름에서 필요한 데이터를 추출하여 요청을 ..." }, { "title": "Session VS JWT(Json Web Token)", "url": "/posts/SessionAndJwt/", "categories": "Network", "tags": "", "date": "2020-09-04 00:00:00 +0800", "snippet": "오늘은 서버와 클라이언트의 인증을 구현하는데 있어서, session과 JWT의 동작방식과 차이점에 대하여 공부해보았다.Session 기반 인증 클라이언트에서 서버로 username, password를 보낸다. 서버는 유저의 로그인정보가 일치하면, session id를 생성하여 메모리에 저장한다. 서버는 클라이언트에게 session id가 담긴 cookie를 전송한다. 클라이언트가 로그인이 되어있는동안, 클라이언트는 서버에 요청할때마다 session id를 함께 전송한다. ..." }, { "title": "Test Strategy", "url": "/posts/test-strategy/", "categories": "Test", "tags": "", "date": "2017-08-19 00:00:00 +0800", "snippet": "Unit Test프로그램의 기본단위인 모듈(코드) 수준에서 시작한다.Integration Test단위 검사 후 모듈을 결합하여 전체 시스템에 대해 검사한다.Stub주요 제어 모듈이 정상적으로 검사될 수 있도록, 일시적으로 필요한 조건만을 가지고 임시로 제공되는 가짜 모듈" }, { "title": "객체지향 기법의 기본 원칙", "url": "/posts/%EA%B0%9D%EC%B2%B4%EC%A7%80%ED%96%A5-%EA%B8%B0%EB%B2%95%EC%9D%98-%EA%B8%B0%EB%B3%B8-%EC%9B%90%EC%B9%99/", "categories": "SoftwareEngineering", "tags": "", "date": "2017-08-19 00:00:00 +0800", "snippet": "캡슐화(Encapsulation)데이터와 데이터를 처리하는 함수를 하나로 묶는 것정보은닉(Information Hiding)다른 객체에게 자신의 정보를 숨기고 자신의 연산만을 통하여 접근추상화(Abstraction)객체의 속성 중 가장 중요한 것에만 중점을 두어 모델화 하는것상속성(Inheritence)이미 정의된 상위클래스의 모든 속성과 연산을 하위 클래스가 물려받는 것다형성(Polymorphism)하나의 메시지에 대해 각 객체가 가지고 있는 고유한 방법으로 응답할 수 있는 능력" }, { "title": "소프트웨어 생명 주기모형", "url": "/posts/%EC%86%8C%ED%94%84%ED%8A%B8%EC%9B%A8%EC%96%B4-%EC%83%9D%EB%AA%85-%EC%A3%BC%EA%B8%B0%EB%AA%A8%ED%98%95/", "categories": "SoftwareEngineering", "tags": "", "date": "2017-08-19 00:00:00 +0800", "snippet": "폭포수 모형 소프트웨어 개발을 각 단계를 확실히 매듭짓고 그 결과를 철저하게 검토하여 승인 과정을 거친 후에 다음 단계를 진행하며 이전 단계로 넘어갈 수 없는 방식이다. 장점 단계별 정의가 분명하고, 전체 공조의 이해가 용이하다. 단점단계별로 오류 없이 다음 단계로 진행해야 하는데 현실적으로 오류 없이 다음 단계로 진행하기는 어렵다. 프로토타입 모형 실제 개발될 소프트웨어에 대한 견본(시제)품을 만들어 최종 결과물을 예측하는 모형이다. 장점요구사항을 충실히 반영, 요구사..." }, { "title": "Transaction", "url": "/posts/transaction/", "categories": "Database, Theory", "tags": "", "date": "2017-08-18 00:00:00 +0800", "snippet": "정의데이터베이스의 상태를 변환시키는 하나의 논리적 기능을 수행하기 위한 작업의 단위트랜잭션의 필요성 거래의 안정성을 확보할수 있는 방법 작업 수행도중 오류가 발생하면 모든 작업을 원상태로 되돌릴 수 있음특성Atomicity 데이터베이스에 모두 반영되든지 아니면 전혀 반영되지 않아야한다. 트랜잭션 내의 모든 명령은 반드시 완벽히 수행되어야 하며, 모두가 완벽히 수행하지 않고 어느 하나라도 오류가 발생하면 트랜잭션 전부가 취소되어야 한다.Consistency 성공적으로 완료하면 언제나 일관성 있는 데이터베이스 상태로 변환..." }, { "title": "Translation Process", "url": "/posts/translation-process/", "categories": "Compiler", "tags": "", "date": "2017-07-19 00:00:00 +0800", "snippet": " Scanner의 역할은 character stream을 가지고 token(의미를 가지는 최소단위)을 생성하는것이다. Parser의 역할은 일련의 token들을 가지고 syntax tree/parse tree를 생성하는 것이다. Semantic analyzer는 parse tree를 가지고 프로그램의 의미를 분석하는 일을 한다. Source code optimizer는 syntax tree를 좀더 간략하게 만들고 three-address code를 좀더 심플하게 만드는 역할을 한다..." }, { "title": "Compiler", "url": "/posts/compiler/", "categories": "Compiler", "tags": "", "date": "2017-07-19 00:00:00 +0800", "snippet": "먼저 컴파일러의 목적은 다음과 같다.먼저, 언어는 다음 3가지로 분류할 수 있다. machine language : 컴퓨터가 직접 실행 할 수 있는 프로그램 assembly language : 기계어 프로그램에서 명령과 메모리주소를 심볼 형태로 표시(특정 기계에 종속) high level language : 기계와 독립적, 간결하고 자연어와 유사컴파일러의 목적은 high level language를 machine language로 번역하는것이다.컴파일러와 관련된 프로그램은 아래와 같다. Interpre..." }, { "title": "화이트 박스와 블랙 박스 테스트의 정의와 차이점", "url": "/posts/%ED%99%94%EC%9D%B4%ED%8A%B8-%EB%B0%95%EC%8A%A4%EC%99%80-%EB%B8%94%EB%9E%99-%EB%B0%95%EC%8A%A4-%ED%85%8C%EC%8A%A4%ED%8A%B8%EC%9D%98-%EC%A0%95%EC%9D%98%EC%99%80-%EC%B0%A8%EC%9D%B4%EC%A0%90/", "categories": "SoftwareEngineering", "tags": "", "date": "2017-07-17 00:00:00 +0800", "snippet": "블랙박스 검사(Black-box testing) 소프트웨어가 수행할 특정 기능을 알기 위해서 각 기능이 완전히 작동되는 것을 입증하는 검사로서, 기능 검사라고도 함. 소프트웨어의 내부를 보지 않고, 입력과 출력값을 확인하여,기능의 유효성을 판단화이트박스 테스트 모듈의 원시 코드를 오픈시킨 상태에서 원시코드의 논리적인 모든 경로를 검사하여 검사 사례를 설계하는 방법 내부 소스코드의 동작을 개발자가 추적 할 수 있기 때문에, 동작의 유효성 뿐만아니라 실행 되는 과정을 살펴봄으로써, 코드가 어떤경로로 실행되며, 불필요한 코드..." }, { "title": "TCP/UDP", "url": "/posts/tcpudp/", "categories": "Network", "tags": "", "date": "2017-07-17 00:00:00 +0800", "snippet": " TCP UDP 연결 지향적 비연결형 서비스 신뢰적인 data 전송 비신뢰적 Error control, flow control, congestion control 제공 오류 복구X, 오류 검출 O, flow control 제공 X Multicast,broadcast 지원 X Multicast,broadcast 지원 " }, { "title": "OSI 7계층", "url": "/posts/osi-7%EA%B3%84%EC%B8%B5/", "categories": "Network", "tags": "", "date": "2017-07-17 00:00:00 +0800", "snippet": "OSI(Open System interconnection) Application : 받은 message 사용용도 결정 Presentation : 데이터 포맷과 코딩방식 결정 Session : 종단간 data를 주고받는 방식 결정(상호교대, 일방적) Transport : 종단간 process 사이에서 신뢰성 있는 data 교환(end-to-end delivery)(ex. TCP,UDP) Network : logical addressing, 목적지까지 data를 전달하는 책임(ex. IP) Data link : phys..." }, { "title": "MAC address, IP address", "url": "/posts/mac-address-ip-address/", "categories": "Network", "tags": "", "date": "2017-07-17 00:00:00 +0800", "snippet": "MAC Address MAC 주소는 일반적으로 제조업체의 등록된 식별 번호로 인코딩되며 이를 BIA(burned-in address)로 부를 수 있다. 또, 이더넷 하드웨어 주소(Ethernet hardware address, EHA), 하드웨어 주소, 물리 주소(메모리 물리 주소와 다름)로 부르기도 한다 IP Address인터넷상에서 라우팅을 효율적으로 하기 위하여 물리적인 네트웍 주소와 일치하는 개념으로 부여된 32 비트의 주소가 IP 주소 IP Address가 MAC address에 비해..." }, { "title": "Flow control, congestion control", "url": "/posts/flow-control-congestion-control/", "categories": "Network", "tags": "", "date": "2017-07-17 00:00:00 +0800", "snippet": "Flow control TCP의 수신버퍼의 오버플로우를 방지 TCP는 상대 TCP에게 rwnd값(수신할 수 있는 data byte용량)을 알려줌 각 TCP 연결당 독립적으로 관리Congestion Control 네트워크의 혼잡을 감지 네트워크는 명시적으로 feedback을 제공해주지 않음,종단 TCP가 네트워크 혼잡을 추정 혼잡의 징후 : Lost packet(라우터에서 buffer overflow 일어났다고 추정), Long delays(queuing in router buffers) cwnd(congestion..." }, { "title": "SW에서 모듈화와 잘하기 위한 조건", "url": "/posts/sw%EC%97%90%EC%84%9C-%EB%AA%A8%EB%93%88%ED%99%94%EC%99%80-%EC%9E%98%ED%95%98%EA%B8%B0-%EC%9C%84%ED%95%9C-%EC%A1%B0%EA%B1%B4/", "categories": "SoftwareEngineering", "tags": "", "date": "2017-07-16 00:00:00 +0800", "snippet": "모듈화 모듈화는 소프트웨어를 각 기능별로 분할하는 것을 의미하며, 각 기능별로 분할한 것을 모듈이라고 한다. 모듈화를 수행하면 소프트웨어의 복잡도가 감소하고, 변경이 쉬우며 프로그램 구현이 용이잘하기 위한 조건 모듈이 하나의 기능만을 수행하고 다른 모듈과의 과도한 상호작용을 배제함 모듈을 독립성있게 만듬.(모듈을 수정하더라도 다른 모듈들에게는 거의 영향을 미치지 않으며, 오류가 발생해도 쉽게 발견할 수 있고 해결할 수 있음) 모듈의 독립성을 높이려면 모듈의 결합도(Coupling)를 약하게 하고 응집도(Cohensio..." }, { "title": "Sequence Diagram, Class Diagram", "url": "/posts/sequence-diagram-class-diagram/", "categories": "SoftwareEngineering", "tags": "", "date": "2017-07-16 00:00:00 +0800", "snippet": "시퀀스 다이어그램클래스 인스턴스(오브젝트) 간의 메시지를 표시하는 다이어그램이다.클래스 다이어그램클래스 관계를 표시해주는 다이어그램" }, { "title": "git repository를 bitbucket에서 github로 옮기는 방법", "url": "/posts/git-repository%EB%A5%BC-bitbucket%EC%97%90%EC%84%9C-github%EB%A1%9C-%EC%98%AE%EA%B8%B0%EB%8A%94-%EB%B0%A9%EB%B2%95/", "categories": "Git", "tags": "", "date": "2017-07-14 00:00:00 +0800", "snippet": " Make a bare mirrored clone of the repository git clone --mirror [bitbucket URL]cd repository-to-mirror.git git remote set-url --push origin [github URL] Set the push location to your mirror git push --mirror " }, { "title": "세마포어와 구현방법 2가지", "url": "/posts/%EC%84%B8%EB%A7%88%ED%8F%AC%EC%96%B4%EC%99%80-%EA%B5%AC%ED%98%84%EB%B0%A9%EB%B2%95-2%EA%B0%80%EC%A7%80/", "categories": "OS", "tags": "", "date": "2017-07-13 00:00:00 +0800", "snippet": "정의S는 정수값을 가지는 변수이며, 다음과 같이 P와 V라는 명령에 의해서만 접근할 수 있다. (P와 V는 각각 try와 increment를 뜻하는 네덜란드어 Proberen과 Verhogen의 머릿글자를 딴 것이다.)P는 임계 구역에 들어가기 전에 수행되고, V는 임계 구역에서 나올 때 수행된다. 이때 변수 값을 수정하는 연산은 모두 원자성을 만족해야 한다. 다시 말해, 한 프로세스(또는 스레드)에서 세마포어 값을 변경하는 동안 다른 프로세스가 동시에 이 값을 변경해서는 안 된다.구현하는 방법 최초 제시된 방법은 바쁜 대기..." }, { "title": "Paging과 TLB", "url": "/posts/paging%EA%B3%BCtlb/", "categories": "OS", "tags": "", "date": "2017-07-13 00:00:00 +0800", "snippet": "Paging가상기억장치를 모두 같은 크기의 페이지 블록으로 편성하여, 각각의 페이지 블록들이 실제 물리 프레임에 맵핑 되도록 구성하는 기법, 논리주소 공간이 한 연속적인 공간에 모여 있어야 하는 제약조건을 없앤다.Paging을 할때 어떻게 실제 메모리 주소에 데이터를 전송하는가?페이지 번호와 페이지 변위로 구성된 가상주소를 가지고 page table에 접근하여, page 번호와 일치되는 행의 프레임 번호를 찾고 그 위치와 page offset을 더하여 실제 메모리 주소에 접근한다.Page table에 저장되는 항목page 번호..." }, { "title": "시스템 콜과 인터럽트", "url": "/posts/%EC%8B%9C%EC%8A%A4%ED%85%9C-%EC%BD%9C%EA%B3%BC-%EC%9D%B8%ED%84%B0%EB%9F%BD%ED%8A%B8/", "categories": "OS", "tags": "", "date": "2017-07-13 00:00:00 +0800", "snippet": "시스템 콜 프로그래밍 언어에서 운영체제(커널)의 서비스를 호출하여 사용하는 것을 말한다. 만약 일반 응용 프로그램이 시스템의 자원을 사용하여 작업을 하려고 한다면 시스템 콜을 사용하여 작업을 한다.인터럽트 프로세서가 프로그램을 실행 도중 하드웨어나 소프트웨어의 문제 때문에 프로그램이 실행되고 있던 순서를 변경하여 좀 더 급한 이벤트를 수행한 후에 원래의 프로그램으로 복귀하여 나머지 프로그램을 수행하는것을 말한다. 인터럽트가 발생하면 현재 위치가 자동으로 인터럽트의 스택에 복귀주소로써 저장되어 인터럽트의 끝에서 복귀 명령..." }, { "title": "Virtual memory에서 page replacement 정책", "url": "/posts/virtual-memory%EC%97%90%EC%84%9C-page-replacement-%EC%A0%95%EC%B1%85/", "categories": "OS", "tags": "", "date": "2017-07-13 00:00:00 +0800", "snippet": "FIFO memory에 올라온 시간이 가장 오래된 page를 victim으로 선정 optimal 하지는 않지만 correctnesss에 영향을 주지는 않음 단점 : Belady’s anomaly 발생 Belady’s anomaly란? frame 수는 증가했지만, page fault는 오히려 증가하는 현상Optimal Page Replacement 가장 오랜기간동안 사용되지 않을 page를 선택 할당된 frame수가 고정일때 가장 낮은 page 부재율을 보장 ..." }, { "title": "page table 구조", "url": "/posts/page-table-%EA%B5%AC%EC%A1%B0/", "categories": "OS", "tags": "", "date": "2017-07-13 00:00:00 +0800", "snippet": "Page Table Structure1. hierarchical paging(계층적 페이징) 32비트 컴퓨터에선 페이지 테이블은 4MB정도로 크다. 페이지 테이블을 작은 조각으로 나눈다. 페이지 테이블 자체가 다시 페이지화 되는 것. 단점 계층이 깊어질수록, 페이지 접근 시간이 늘어난다. 64비트 컴퓨터의 경우 페이지 크기가 어마어마하게 크다. 너무 많은 메모리 접근을 요구하므로 구현이 불가능하다. 2. has..." }, { "title": "DB와 File System의 차이", "url": "/posts/db%EC%99%80-file-system%EC%9D%98-%EC%B0%A8%EC%9D%B4/", "categories": "Database, Theory", "tags": "", "date": "2017-07-13 00:00:00 +0800", "snippet": "파일 시스템:장점 처리속도가 DB에 비해 빠르다. 구현이 간편하다 비용이 저렴하다.단점 자료의 중복 발생 데이터 무결성,일관성 보장의 어려움 개발 생산성을 기대하기 어려움데이터베이스장점 자료의 독립성 데이터 무결성 보장 개발 생산성 보장 (표준 SQL, 개발기간 절감, 운영비용 절감)단점 시스템의 부하 및 복잡성 별도의 관리 이력 필요 추가 도입비용 발생출처" }, { "title": "Data normalizaton", "url": "/posts/data-normalizaton%EC%9D%98-%EC%A0%95%EC%9D%98%EC%99%80-%ED%95%84%EC%9A%94%ED%95%9C-%EC%9D%B4%EC%9C%A0/", "categories": "Database, Theory", "tags": "", "date": "2017-07-13 00:00:00 +0800", "snippet": "정의데이터베이스 내의 애트리뷰트 간의 종속성을 분석해서 하나의 종속성이 하나의 릴레이션으로 표현되도록 분리하는 과정목적 중복된 데이터를 제거 삽입,삭제,갱신 이상의 발생을 방지Anomaly의 개념 및 종류 삽입이상 : 릴레이션에 데이터를 삽입할때 의도와는 상관없이 원하지 않은 값들도 함께 삽입 삭제이상 : 릴레이션에서 한 튜플을 삭제할 때 의도와는 상관없는 값들도 함께 삭제되는 연쇄 삭제 현상이 발생 갱신이상 : 릴레이션에서 튜플에 있는 속성값을 갱신할 때 일부 튜플의 정보만 갱신되어 정보..." }, { "title": "Schema,Data Independence", "url": "/posts/data-independence/", "categories": "Database, Theory", "tags": "", "date": "2017-07-13 00:00:00 +0800", "snippet": "Schema 데이터베이스에서 자료의 구조, 자료의 표현 방법, 자료 간의 관계를 정의한 것을 말하는 전산학 용어이다. 데이터베이스 관리 시스템(DBMS)이 주어진 설정에 따라 데이터베이스 스키마를 만들어 내며, 데이터베이스 사용자가 자료를 저장, 조회, 삭제, 변경할 때 DBMS는 그것이 생성한 데이터베이스 스키마를 참조하여 명령을 수행한다. 자료의 독립성(data independence) 일반적으로 자료의 독립성이란 어느 단계의 스키마를 바꾸었을 때, 그 위 단계의 스키마에 영향을 주지 않고 결국 응..." }, { "title": "스크립트언어와 컴파일언어의 차이점", "url": "/posts/%EC%8A%A4%ED%81%AC%EB%A6%BD%ED%8A%B8%EC%96%B8%EC%96%B4%EC%99%80-%EC%BB%B4%ED%8C%8C%EC%9D%BC%EC%96%B8%EC%96%B4%EC%9D%98-%EC%B0%A8%EC%9D%B4%EC%A0%90/", "categories": "Compiler", "tags": "", "date": "2017-07-12 00:00:00 +0800", "snippet": "스크립트 언어 php, javascript, python … 컴파일 과정을 거치지 않고 실시간으로 텍스트를 분석하며 실행 코드에 문법 오류 가있을 경우 실행시점에 발견됨 스크립트 엔진이 포팅되어 있는 모든 운영체제에서 실행 가능 컴파일 언어보다 실행속도가 느림 컴파일 언어: 컴파일러에 의해 기계어로 번역된 채로 실행됨 문법오류가 컴파일 시점에 발견됨 목표로 한 운영체제에서만 실행가능 실행이 빠르나, 수정이 빈번하게 발생할..." }, { "title": "캐시가 필요한 이유와 Cache Hit Ratio", "url": "/posts/%EC%BA%90%EC%8B%9C%EA%B0%80-%ED%95%84%EC%9A%94%ED%95%9C-%EC%9D%B4%EC%9C%A0%EC%99%80-cache-hit-ratio/", "categories": "Architecture", "tags": "", "date": "2017-07-12 00:00:00 +0800", "snippet": "캐시가 필요한 이유대부분 프로그램은 한번 사용한 데이터를 다시 사용할 가능성이 높고, 그 주변의 데이터도 곧 사용할 가능성이 높은 데이터 지역성을 가지고 있다.데이터 지역성을 활용하여 메인 메모리에 있는 데이터를 캐시 메모리에 불러와 두고, CPU가 필요한 데이터를 캐시에서 먼저 찾도록 하면 시스템 성능을 향상시킬 수 있다. cache hit : 참조하려는 데이터가 캐시에 존재할때 캐시 히트 cache miss : 참조하려는 데이터가 캐시에 존재하지 않을때 캐시 미스 Cache hit ratio cac..." } ]
