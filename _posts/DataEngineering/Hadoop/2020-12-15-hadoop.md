---
layout: post
title: "Hadoop Overview"
date: 2020-12-15 11:17:00 +0900
categories: [DataEngineering,Hadoop]
---

## 왜 하둡을 쓰는가?
- 빅데이터 처리가능 - eg. 하루에 terabyte

- Horizontal scaling으로 계속 성능을 linear하게 향상가능

    - Disk seek time 감소

    - Hardware failure에 대해 유연함

    - Processing times이 단일 노드에 비해 빠름(병렬처리)

    - Vertical scaling으로는 위의 장점을 얻는것이 불가능하다.

## 주요 컴포넌트

- HDFS : distributed data storage

- YARN : computing cluster의 resouce를 관리해주는 시스템(어떤 리소스가 available, not available인지 트래킹), resource negotiator라 부름.

- MapReduce : 전체 클러스터에 데이터를 분산시켜서 작업을 수행하는 프로그래밍 모델, mapper와 reducer로 구성

- Pig : python이나 java코드 없이 SQL과 같은 언어로 MapReduce 작업을 가능하게 하는 High level programming api, 실제로는 내부에서 스트립트 언어로 변환됨.

- Hive : file system이 마치 SQL database처럼 보이도록 함, shell client나 ODBC와 같은 프로그램으로 접속가능, Hadoop cluster에 저장되있는 데이터를 대상으로 SQL query 실행가능

- Apache Ambari : 하둡클러스터에 대한 뷰를 제공함.(하둡 시스템에 대한 프론트엔드), Hortonworks가 사용

- Mesos : YARN과 같이 resource negotiator

- Spark :  클러스터에 있는 데이터를 reliably,효율적으로 처리 하는데 사용. YARN 또는 Mesos위에서 동작. Scale,Python, Java로 스크립트 작성가능.
SQL queries, Machine learning, Streaming data 처리 가능

- TEZ : Spark처럼 directed acyclic graph(쿼리를 실행하는데 optimal plan 생성)를 사용, 속도를 증가시키기 위해서 Hive와 보통 함께 사용된다.

- HBase : No SQL database, columnar data store(열기반 데이터 스토어), 클러스터에 있는 데이터들을 노출가능

- Apache Storm : Streaming data를 처리

- oozie : 클러스터에 작업을 스케줄링해줌. Hive->Pig->Spark->HBase 와 같이 여러 작업들 간에 스케줄링을 해줌.

- Zookeeper : 어느 노드가 살아있고 죽었는지 트래킹하는 역할

- Data Ingestion : 외부에 있는 데이터를 하둡 클러스터에 데이터를 저장하는 역할

    - Sqoop : ODBC,JDBC(legacy db)와 하둡의 커넥터 역할

    - Flume : 대용량의 web log를 클러스터에 보냄

    - Kafka

- External Data Storage

    - MySQL : Sqoop을 이용하여 클러스터에 있는 데이터를 MySQL로 저장가능

    - Cassandara, MongoDB : 실시간으로 데이터를 노출가능

- Query Processor

    - Impala

    - Hive