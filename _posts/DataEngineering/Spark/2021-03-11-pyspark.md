---
layout: post
title: "Python to RDD communications"
date: 2021-03-11 21:26:00 +0900
categories: [DataEngineering,Spark]
---

## Py4J와 Pyspark
Py4J는 Python 인터프리터에서 실행되는 Python
프로그램이 JVM(Java Virtual Machine)의 Java 객체에 동적으로 액세스가 가능하게 한다. 또한 Py4J
는 자바 프로그램이 Python 객체와 연동할 수 있게
하며, BSD 라이센스하에 배포된다. Method는
Python interpreter에 있는 Java 객체와 Java collection이 표준 Python collection method를 통해 액세스 할 수 있는 것처럼 호출된다. PySpark는 Spark의 Java API 위에 구축되었으며 데이터를 Python에서 처리하고 JVM에서caching 및 shuffling되게 한다. Shuffling은 partition 간에 데이터를 재분배하는 프로세스이다

## Python to RDD communications
PySpark 프로그램이 RDD를 사용하여 실행될때마다, job을 실행하는데 큰 오버헤드가 발생한다. PySpark driver에서 ```Spark Context```는 ```Py4j```를 사용하여 ```JavaSparkContext```를 사용하는 JVM을 실행한다. 모든 RDD transformation들은 처음에는 Java에 있는 ```PythonRDD``` 객체에 맵핑된다.
이 task가 Spark Worker들에 푸시되면, ```PythonRDD``` 객체들은 Python ```subprocesses```를 생성하고 (pipe를 사용하여) 코드와 데이터를 python process로 전달하게 되고, python process에서 작업이 실행되게 됩니다.

![img](https://static.packt-cdn.com/products/9781786463708/graphics/B05793_03_01.jpg)

이 방법이 PySpark이 여러 워커에 있는 Python subprocesses에게 데이터 처리를 분산시키지만, context switching이 많이 일어나고 Python과 JVM간에 communication 오버헤드가 발생한다.

## 출처
[Spark 기반에서 Python과 Scala API의 성능 비교 분석](https://www.koreascience.or.kr/article/JAKO202010163508830.pdf)
[https://subscription.packtpub.com/book/big_data_and_business_intelligence/9781786463708/3/ch03lvl1sec17/python-to-rdd-communications](https://subscription.packtpub.com/book/big_data_and_business_intelligence/9781786463708/3/ch03lvl1sec17/python-to-rdd-communications)